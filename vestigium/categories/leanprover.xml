<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium (Publicaciones sobre LeanProver)</title><link>https://jaalonso.github.io/vestigium/</link><description></description><atom:link href="https://jaalonso.github.io/vestigium/categories/leanprover.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Fri, 13 Jun 2025 16:39:39 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Reseña de «Mathesis: Towards formal theorem proving from natural languages»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural
languages&lt;/a&gt;», se aborda la limitación clave de los demostradores de
teoremas: su dependencia de enunciados ya formalizados. El trabajo se
centra en el paso crítico de la 'autoformalización' —la traducción a un
lenguaje formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;— y presenta Mathesis, un sistema integral
diseñado para automatizar todo el proceso.&lt;/p&gt;
&lt;p&gt;El sistema introduce un Mathesis-Autoformalizer entrenado mediante
aprendizaje por refuerzo para optimizar la traducción a código Lean. Su
rendimiento se evalúa con LeanScorer, y se pone a prueba en
Gaokao-Formal, un nuevo y exigente banco de pruebas. Finalmente,
Mathesis-Prover genera la demostración completa en Lean, asegurando que
la prueba final sea verificable.&lt;/p&gt;
&lt;p&gt;Los resultados demuestran que Mathesis alcanza un rendimiento de
vanguardia en varios bancos de prueba. El análisis revela una conclusión
crucial: las mejoras en la autoformalización impactan el éxito final
mucho más que las mejoras en el demostrador. Esto se explica porque si
el problema se traduce incorrectamente a código Lean, el demostrador
recibe una tarea mal planteada y no puede generar una prueba válida, sin
importar su potencia. El trabajo confirma así que una traducción inicial
de alta calidad es el factor más determinante para el éxito del proceso.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</guid><pubDate>Fri, 13 Jun 2025 16:35:00 GMT</pubDate></item><item><title>Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt;», los autores investigan la aplicabilidad de
los modelos de lenguaje grandes multimodales (MLLMs) al problema de la
demostración automática de teoremas que involucran componentes tanto
textuales como visuales. Motivados por las limitaciones de los enfoques
puramente textuales en dominios como la geometría, donde los diagramas
constituyen información esencial, desarrollan un marco de evaluación
sistemático para esta clase de problemas.&lt;/p&gt;
&lt;p&gt;La contribución principal consiste en la construcción de &lt;a href="https://github.com/Zhitao-He/MATPBench"&gt;MATP-BENCH&lt;/a&gt;, un
conjunto de datos que contiene más de 1000 problemas matemáticos
multimodales formalizados en tres asistentes de demostración: &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Rocq"&gt;Coq&lt;/a&gt; e &lt;a href="https://en.wikipedia.org/wiki/Isabelle_(proof_assistant)"&gt;Isabelle/HOL&lt;/a&gt;. El corpus abarca problemas de complejidad variable,
desde el nivel de secundaria hasta competiciones matemáticas avanzadas,
proporcionando así un banco de pruebas comprehensivo para evaluar
capacidades de razonamiento multimodal.&lt;/p&gt;
&lt;p&gt;Los experimentos incluyen seis modelos representativos: tres con
capacidades especializadas de razonamiento (OpenAI-o1,
Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking) y tres sin estas
capacidades (GPT-4.1, Qwen2.5-VL-Instruct-70B,
Llama3.2-Vision-Instruct-11B). Los resultados revelan que, si bien los
modelos demuestran competencia en la comprensión de problemas y
formalización de enunciados, exhiben deficiencias significativas en la
construcción de cadenas de inferencia válidas.&lt;/p&gt;
&lt;p&gt;El análisis establece que la principal limitación no radica en las
capacidades de percepción visual sino en la insuficiencia del
razonamiento simbólico formal. Los autores concluyen que los MLLMs
actuales no constituyen demostradores automáticos efectivos para
problemas multimodales, identificando la brecha entre comprensión
multimodal y razonamiento lógico como el desafío fundamental a resolver.&lt;/p&gt;
&lt;p&gt;MATP-BENCH se posiciona como el primer banco de prueba estándar para
este dominio, proporcionando una base metodológica para la evaluación de
futuros desarrollos en demostración automática multimodal.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>CoqProver</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>MLLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</guid><pubDate>Fri, 13 Jun 2025 15:10:00 GMT</pubDate></item><item><title>Readings shared June 12, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 12 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/R2t9ZRWiWEk"&gt;Formalizing the divided power envelope in Lean&lt;/a&gt;. ~ María Inés de Frutos Fernández. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/YtbfIjgzNDI"&gt;Lean meta-theory: The proofs behind the proofs&lt;/a&gt;. ~ Mario Carneiro. #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/litexlang/golitex"&gt;Litex: Scale formal reasoning in AI age&lt;/a&gt;. ~ Jiachen Shen. #Logic #ATP #LitexLang&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neus-2025.github.io/files/papers/paper_33.pdf"&gt;Lean Copilot: Large language models as copilots for theorem proving in Lean&lt;/a&gt;. ~ Peiyang Song, Kaiyu Yang, Anima Anandkumar. #ITP #LeanProver #LLMs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3713082.3730382"&gt;Can large language models verify system software? A case study using FSCQ as a benchmark&lt;/a&gt;. ~ Jianxing Qin et als. #LLMs #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muratkasimov.art/Ya/Articles/Reinventing-records-and-variants"&gt;Reinventing records and variants&lt;/a&gt;. ~ Murat Kasimov. #Haskell #FunctionalProgramming&lt;/li&gt;
&lt;/ul&gt;</description><category>ATP</category><category>CoqProver</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</guid><pubDate>Fri, 13 Jun 2025 08:40:00 GMT</pubDate></item><item><title>Readings shared June 11, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/12-readings_shared_06-11-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 11 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.08321"&gt;LeanTutor: A formally-verified AI tutor for mathematical proofs&lt;/a&gt;. ~ Manooshree Patel et als. #ITP #LeanProver #Math #AIforMath #Teaching&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nielsvoss/lean-pitfalls"&gt;Common Lean pitfalls&lt;/a&gt;. ~ Niels Voss. #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/"&gt;Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library&lt;/a&gt;. ~ Brenda Potts. #ITP #LeanProver #RustLang&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.08294v1"&gt;Z3Guide: A scalable, student-centered, and extensible educational environment for logic modeling&lt;/a&gt;. ~ Ruanqianqian Huang, Ayana Monroe, Peli de Halleux, Sorin Lerner, Nikolaj Bjørner. #Logic #SMT #Z3 #Teaching&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hal.univ-lille.fr/hal-05061202v1/file/main.pdf"&gt;Martin Davis: An overview of his work in logic, computer science, and philosophy&lt;/a&gt;. ~ Liesbeth De Mol, Yuri V. Matiyasevich, Eugenio G. Omodeo, Alberto Policriti, Wilfried Sieg, Elaine J. Weyuker. #Logic #Math #CompSci&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/"&gt;El futuro del razonamiento matemático: Integrando IA y Lean&lt;/a&gt;. #IA #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/"&gt;Reseña de 'LeanTutor: A formally-verified AI tutor for mathematical proofs'&lt;/a&gt;. #ITP #LeanProver #Math #AIforMath #Teaching&lt;/li&gt;
&lt;/ul&gt;</description><category>AIforMath</category><category>CompSci</category><category>IA</category><category>ITP</category><category>LeanProver</category><category>Logic</category><category>Math</category><category>RustLang</category><category>SMT</category><category>Z3</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/12-readings_shared_06-11-25/</guid><pubDate>Thu, 12 Jun 2025 06:16:00 GMT</pubDate></item><item><title>Reseña de 'LeanTutor: A formally-verified AI tutor for mathematical proofs'</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El artículo "&lt;a href="https://arxiv.org/abs/2506.08321"&gt;LeanTutor: A formally-verified AI tutor for mathematical
proofs&lt;/a&gt;" aborda un problema común en la educación matemática: los
estudiantes tienen dificultades para aprender demostraciones.
Actualmente existen dos tipos de herramientas, pero ninguna funciona
bien para enseñar. Los chatbots como ChatGPT son fáciles de usar pero
dan respuestas directas o incorrectas, sin ayudar realmente al
aprendizaje. Los asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; verifican las
matemáticas perfectamente, pero son demasiado complicados para
principiantes. Se necesita una herramienta que combine lo mejor de
ambos: la facilidad del lenguaje natural y la precisión de la
verificación formal.&lt;/p&gt;
&lt;p&gt;Los autores crearon LeanTutor, un sistema que funciona como tutor
inteligente combinando lenguaje natural con verificación formal. El
sistema tiene tres partes que trabajan juntas. Primero, el
'autoformalizador' toma lo que escribe el estudiante en lenguaje normal
y lo convierte a código Lean para verificar si es correcto. Si hay un
error, el 'generador del siguiente paso' calcula cuál sería la respuesta
correcta. Finalmente, el 'generador de retroalimentación' convierte esta
información técnica en consejos útiles para el estudiante, dándole
pistas sin revelar directamente la solución.&lt;/p&gt;
&lt;p&gt;Los investigadores probaron LeanTutor usando un nuevo conjunto de datos
llamado PeanoBench y los resultados fueron positivos. El sistema logró
convertir correctamente la mayoría de los pasos que escribían los
estudiantes y detectó muchos errores. Cuando compararon la
retroalimentación de LeanTutor con otros sistemas, encontraron que era
más precisa y útil para los estudiantes. Los autores concluyen que este
enfoque de combinar IA conversacional con verificación formal es una
buena dirección para crear mejores herramientas educativas.&lt;/p&gt;
&lt;p&gt;Este trabajo presenta una idea muy buena para mejorar la educación
matemática. La principal fortaleza es que logra combinar de manera
inteligente la facilidad de uso del lenguaje natural con la precisión
matemática de Lean. Sin embargo, también tiene algunas limitaciones
importantes. El sistema necesita tener de antemano la solución correcta
del problema, y asume que los pasos del estudiante se pueden traducir
directamente a código Lean, lo que podría no funcionar en situaciones
más complejas. A pesar de estas limitaciones, LeanTutor es un buen
primer paso que muestra cómo la IA puede ayudar a enseñar matemáticas de
forma más efectiva y segura.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>Teaching</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</guid><pubDate>Wed, 11 Jun 2025 17:26:00 GMT</pubDate></item><item><title>Readings shared June 10, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 10 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lawrencecpaulson.github.io//2025/06/09/Inductive_Definitions.html"&gt;Inductive definitions&lt;/a&gt;. ~ Lawrence Paulson. #ITP #IsabelleHOL #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project: advancing collaborative mathematical research at scale&lt;/a&gt;. ~ Terence Tao et als. #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathscholar.org/2025/06/new-ai-stuns-mathematicians-with-its-problem-solving-skill/"&gt;New AI stuns mathematicians with its problem-solving skill&lt;/a&gt;. ~ David H Bailey. #AI #LLMs #Math #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07477"&gt;Premise selection for a Lean hammer&lt;/a&gt;. ~ Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck. #ITP #LeanProver #AI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04592v1"&gt;Safe: Enhancing mathematical reasoning in large language models via retrospective step-aware formal verification&lt;/a&gt;. ~ Chengwu Liu et als. #LLMs #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;. ~ Thomas Hubert. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative discovery&lt;/a&gt;. ~ Mateja Jamnik. #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04575v1"&gt;Are LLMs reliable translators of logical reasoning across lexically diversified contexts?&lt;/a&gt; ~ Qingchuan Li et als. #LLMs #Math #ATP #Prover9&lt;/li&gt;
&lt;li&gt;&lt;a href="https://coyotetracks.org/blog/dr-neckbeard-emacs/"&gt;Dr. Neckbeard, or how I learned to stop worrying and love Emacs&lt;/a&gt;. ~ Watts Martin. #Emacs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bib.us.es/sites/bib3.us.es/files/investiga52.pdf"&gt;Revistas, editoriales y congresos depredadores&lt;/a&gt;. #Investigación&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/"&gt;AlphaProof: Aprendizaje por refuerzo aplicado a la demostración matemática&lt;/a&gt;. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/"&gt;El futuro de las matemáticas: Descubrimiento colaborativo entre humanos y máquinas&lt;/a&gt;. #AIforMath #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/"&gt;El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)&lt;/a&gt;. #AIforMath #ITP #LeanProver #Math&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>AlphaProof</category><category>ATP</category><category>Emacs</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Prover9</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</guid><pubDate>Wed, 11 Jun 2025 09:06:00 GMT</pubDate></item><item><title>El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Hoy, en su conferencia "&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project&lt;/a&gt;", &lt;a href="https://en.wikipedia.org/wiki/Terence_Tao"&gt;Terence Tao&lt;/a&gt;
defendió que la investigación matemática debe evolucionar hacia un
modelo colaborativo a gran escala, semejante al empleado en otras
disciplinas científicas. Esta transformación requiere el uso de
herramientas modernas como plataformas colaborativas (&lt;a href="https://github.com/teorth/equational_theories"&gt;GitHub&lt;/a&gt;),
asistentes de prueba formales (&lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;) y automatización mediante
inteligencia artificial. El proyecto &lt;a href="https://teorth.github.io/equational_theories/"&gt;ETP (Equational Theories Project)&lt;/a&gt;
constituye un ejemplo paradigmático de esta nueva aproximación a la
investigación matemática.&lt;/p&gt;
&lt;p&gt;El proyecto nació de una pregunta aparentemente simple planteada en el
foro MathOverflow, pero pronto adquirió una dimensión extraordinaria:
mapear completamente el "gráfico de implicaciones" entre 4,692 leyes
algebraicas únicas dentro de estructuras elementales denominadas
magmas. Esta ambiciosa meta implicaba resolver más de 22 millones de
problemas individuales, donde cada par de leyes requería encontrar una
prueba de implicación o desarrollar un contraejemplo que la refutara. La
magnitud descomunal de este desafío lo convertía en una tarea imposible
de abordar mediante los métodos tradicionales de investigación
individual o de pequeños equipos.&lt;/p&gt;
&lt;p&gt;La estrategia implementada por el ETP consistió en un flujo de trabajo
híbrido y descentralizado de notable innovación. La componente humana
aprovechó la creatividad de una extensa comunidad de colaboradores para
desarrollar pruebas y contraejemplos ingeniosos, mientras que la
componente computacional empleó masivamente probadores automáticos de
teoremas (ATPs) y otras herramientas para resolver millones de casos más
directos. El elemento fundamental que garantizó la integridad del
proyecto fue la formalización exhaustiva de cada resultado en el
asistente de pruebas Lean, asegurando una corrección absoluta y creando
una base de conocimiento completamente verificada y confiable.&lt;/p&gt;
&lt;p&gt;En el plazo extraordinariamente breve de tres meses, el proyecto logró
resolver prácticamente la totalidad de los 22 millones de problemas
planteados. Además, el proceso de abordar los casos más complejos
estimuló el desarrollo de técnicas matemáticas innovadoras, culminando
con la formulación de un nuevo y fascinante problema abierto. El ETP
demostró que este modelo colaborativo trasciende la mera verificación de
conocimiento existente para convertirse en un motor poderoso de
descubrimiento matemático, estableciendo así un precedente exitoso para
una investigación matemática más abierta, transparente y asistida
computacionalmente.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</guid><pubDate>Tue, 10 Jun 2025 18:00:00 GMT</pubDate></item><item><title>AlphaProof - Aprendizaje por refuerzo aplicado a la demostración matemática</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia de ayer "&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;",
Thomas Hubert de Google DeepMind presentó &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;AlphaProof&lt;/a&gt;, un sistema de
inteligencia artificial que aplica los principios del &lt;a href="https://en.wikipedia.org/wiki/Reinforcement_learning"&gt;aprendizaje por
refuerzo&lt;/a&gt; (RL, del inglés "&lt;em&gt;Reinforcement learning&lt;/em&gt;") al dominio de las
matemáticas formales. El concepto fundamental radica en que los
asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; proporcionan el entorno perfecto
para el RL: un espacio de experimentación masiva con retroalimentación
inequívoca (una prueba matemática es correcta o incorrecta, sin
ambigüedades). Siguiendo el paradigma exitoso de sistemas como AlphaGo
Zero, AlphaProof está diseñado para generar conocimiento matemático de
forma autónoma, trascendiendo la mera imitación de demostraciones
humanas preexistentes.&lt;/p&gt;
&lt;p&gt;La arquitectura de AlphaProof se estructura en un proceso de múltiples
fases que combina diferentes técnicas de aprendizaje
automático. Inicialmente, emplea modelos de lenguaje para autoformalizar
problemas matemáticos expresados en lenguaje natural hacia el código
formal de Lean, generando así un extenso conjunto de datos de
entrenamiento. Su modelo demostrador experimenta dos etapas: primero, un
entrenamiento supervisado utilizando la biblioteca &lt;a href="https://leanprover-community.github.io/mathlib-overview.html"&gt;mathlib&lt;/a&gt;, seguido de
un refinamiento intensivo mediante RL que resuelve millones de problemas
matemáticos. Para desafíos particularmente complejos —como los de la
Olimpiada Internacional de Matemáticas (IMO)—, el sistema implementa una
estrategia de adaptación en tiempo real, generando y resolviendo
múltiples variantes de un problema para desarrollar gradualmente la
intuición necesaria.&lt;/p&gt;
&lt;p&gt;Los resultados validan el potencial transformador de AlphaProof como
herramienta matemática colaborativa. El sistema alcanzó una puntuación
equivalente a una &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;medalla de plata en la IMO&lt;/a&gt; y, durante una demostración
en vivo durante la conferencia, asistió exitosamente a un matemático a
completar los pasos de una prueba compleja relacionada con la función
zeta de Riemann. Hubert enfatiza que el objetivo trasciende las
competiciones académicas: la meta fundamental es contribuir
significativamente a la investigación matemática contemporánea,
convirtiendo AlphaProof en una útil para la comunidad matemática que
facilite el descubrimiento y verificación de nuevas verdades
matemáticas.&lt;/p&gt;</description><category>AI</category><category>AlphaProof</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>RL</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</guid><pubDate>Tue, 10 Jun 2025 11:50:00 GMT</pubDate></item><item><title>Readings shared June 9, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 9 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://emilyriehl.github.io/files/invisible.pdf"&gt;Formalizing invisible mathematics: case studies from higher category theory&lt;/a&gt;. ~ Emily Riehl. #ITP #LeanProver #Math #CategoryTheory&lt;/li&gt;
&lt;li&gt;&lt;a href="https://provables.github.io/sequencelib/"&gt;Sequencelib: A platform for formalizing in Lean 4 sequences from "The On-Line Encyclopedia of Integer Sequences" (OEIS)&lt;/a&gt;. ~ Walter Moreira, Joe Stubbs. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.scientificamerican.com/article/inside-the-secret-meeting-where-mathematicians-struggled-to-outsmart-ai/"&gt;At secret math meeting, researchers struggle to outsmart AI&lt;/a&gt;. ~ Lyndie Chiou. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mmhaskell.com/blog/2025/6/9/spatial-reasoning-with-zigzag-patterns"&gt;Comparing code: Spatial reasoning with zigzag patterns! ~ James Bowen&lt;/a&gt;. #Haskell #FunctionalProgramming #Rust&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@kenichisasagawa/exploring-topological-spaces-with-prolog-a-practical-approach-using-mathematics-with-prolog-b5806bb8b98f"&gt;Exploring topological spaces with Prolog: A practical approach using "Mathematics with Prolog"&lt;/a&gt;. ~ Kenichi Sasagawa. #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2108.09893"&gt;Teaching and learning mathematics with Prolog&lt;/a&gt;. ~ Tom Bensky (2021). #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/09-evaluando-la-ia-con-problemas-matematicos-ineditos-de-nivel-experto/"&gt;Evaluando la IA con problemas matemáticos inéditos de nivel experto&lt;/a&gt;. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/li-12"&gt;Curso "Lógica informática (2012-13)"&lt;/a&gt;. #Lógica #ProgramaciónLógica #Prolog&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/lmf-12"&gt;Curso "Lógica matemática y fundamentos (2012-13)"&lt;/a&gt;. #Lógica #Haskell #ProgramaciónFuncional #Isabelle/HOL&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>CategoryTheory</category><category>FunctionalProgramming</category><category>Haskell</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>LogicProgramming</category><category>Math</category><category>Prolog</category><category>Rust</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</guid><pubDate>Tue, 10 Jun 2025 04:00:00 GMT</pubDate></item><item><title>Readings shared June 8, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 8 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf"&gt;The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity&lt;/a&gt;. ~ Parshin Shojaee et als. #LLMs #Reasoning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/"&gt;Más allá de la "ilusión de pensar"&lt;/a&gt;. #LLMs #Reasoning #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/"&gt;AutoGPS: Un sistema neuro-simbólico para la geometría&lt;/a&gt;. #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/i1m-12"&gt;Curso "Informática (2012-13)"&lt;/a&gt;. #Haskell #ProgramaciónFuncional #Algorítmica #CálculoSimbólico #Maxima&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>Algorithms</category><category>CAS</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Maxima</category><category>Reasoning</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</guid><pubDate>Sun, 08 Jun 2025 04:00:00 GMT</pubDate></item></channel></rss>