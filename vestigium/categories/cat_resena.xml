<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium (Publicaciones sobre Reseña)</title><link>https://jaalonso.github.io/vestigium/</link><description></description><atom:link href="https://jaalonso.github.io/vestigium/categories/cat_resena.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sun, 15 Jun 2025 14:47:49 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Reseña de «Hablemos de Lisp»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/15-hablemos-de-lisp/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El vídeo «&lt;a href="https://youtu.be/qtVjx9mKVoE"&gt;Hablemos de Lisp&lt;/a&gt;» presenta un diálogo que explora la historia,
conceptos fundamentales y legado duradero del lenguaje de programación
&lt;a href="https://es.wikipedia.org/wiki/Lisp"&gt;Lisp&lt;/a&gt;. El análisis comienza con una perspectiva histórica rigurosa,
desmitificando la creencia común de que fue el primer &lt;a href="https://es.wikipedia.org/wiki/Programaci%C3%B3n_funcional"&gt;lenguaje
funcional&lt;/a&gt;. En su lugar, identifica al &lt;a href="https://en.wikipedia.org/wiki/Information_Processing_Language"&gt;IPL (Information Processing
Language)&lt;/a&gt; de &lt;a href="https://en.wikipedia.org/wiki/Herbert_A._Simon"&gt;Herbert Simon&lt;/a&gt; y &lt;a href="https://en.wikipedia.org/wiki/Allen_Newell"&gt;Allen Newell&lt;/a&gt; como su precursor
fundamental.&lt;/p&gt;
&lt;h2&gt;Contexto histórico y pioneros&lt;/h2&gt;
&lt;p&gt;El vídeo establece una distinción crucial entre los diferentes pioneros
de la &lt;a href="https://en.wikipedia.org/wiki/Artificial_intelligence"&gt;inteligencia artificial&lt;/a&gt;: mientras que Simon y Newell sentaron las
bases conceptuales del campo, &lt;a href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)"&gt;John McCarthy&lt;/a&gt; acuñó el término
"inteligencia artificial" y creó LISP, inspirado precisamente por las
capacidades de procesamiento de listas que había demostrado IPL.&lt;/p&gt;
&lt;h2&gt;La naturaleza funcional de LISP&lt;/h2&gt;
&lt;p&gt;Respecto al &lt;a href="https://en.wikipedia.org/wiki/Functional_programming"&gt;paradigma funcional&lt;/a&gt;, el análisis revela que LISP, en sus
primeras etapas, no cumplía estrictamente con los principios de la
programación funcional moderna, como la inmutabilidad y la gestión
explícita de efectos secundarios. La formalización teórica de este
paradigma se atribuye posteriormente a la familia de lenguajes &lt;a href="https://en.wikipedia.org/wiki/ISWIM"&gt;ISWIM&lt;/a&gt;,
propuesta por &lt;a href="https://en.wikipedia.org/wiki/Peter_Landin"&gt;Peter Landin&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Evolución técnica y conceptual&lt;/h2&gt;
&lt;p&gt;La génesis de la implementación de LISP se sigue de &lt;a href="https://justine.lol/sectorlisp/flpl-the-lisp-competitor.pdf"&gt;FLPL (Fortran Lisp
Processing Language)&lt;/a&gt;, un lenguaje intermedio que resultó fundamental
por introducir la expresión condicional, una construcción sintáctica que
más tarde sería adoptada ampliamente por lenguajes imperativos.&lt;/p&gt;
&lt;h2&gt;El momento decisivo: concepto versus implementación&lt;/h2&gt;
&lt;p&gt;Una de las discusiones más reveladoras del vídeo aborda la distinción
entre el concepto original de LISP (1959) y &lt;a href="https://history.siam.org/sup/Fox_1960_LISP.pdf"&gt;su primera implementación
(1960)&lt;/a&gt;. McCarthy había concebido inicialmente una sintaxis de alto
nivel (&lt;a href="https://en.wikipedia.org/wiki/M-expression"&gt;M-expresión&lt;/a&gt;) que se compilaría a una representación simbólica
intermedia (&lt;a href="https://en.wikipedia.org/wiki/S-expression"&gt;S-expresión&lt;/a&gt;). Sin embargo, el éxito de la implementación de
la función &lt;a href="https://en.wikipedia.org/wiki/Eval#Lisp"&gt;eval&lt;/a&gt; puso de manifiesto la profunda simetría entre código y
datos —la &lt;a href="https://en.wikipedia.org/wiki/Homoiconicity"&gt;homoiconicidad&lt;/a&gt;— inherente a la S-expresión.&lt;/p&gt;
&lt;p&gt;Esta propiedad fundamental resultó tan poderosa que llevó al abandono de
la M-expresión, convirtiendo la sintaxis intermedia en el lenguaje de
programación definitivo.&lt;/p&gt;
&lt;h2&gt;Legado e influencia contemporánea&lt;/h2&gt;
&lt;p&gt;El vídeo concluye evaluando el legado perdurable de LISP en la ciencia
de la computación. Se le atribuye la introducción de conceptos
fundamentales como la &lt;a href="https://en.wikipedia.org/wiki/Conditional_(computer_programming)"&gt;expresión condicional&lt;/a&gt; y la recolección automática
de basura (&lt;a href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)"&gt;garbage collection&lt;/a&gt;). Su relevancia actual se manifiesta a
través de sus numerosos &lt;a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)#Major_dialects"&gt;dialectos modernos&lt;/a&gt;, destacando &lt;a href="https://en.wikipedia.org/wiki/Common_Lisp"&gt;Common Lisp&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)"&gt;Scheme&lt;/a&gt;, &lt;a href="https://en.wikipedia.org/wiki/Clojure"&gt;Clojure&lt;/a&gt; y &lt;a href="https://en.wikipedia.org/wiki/Racket_(programming_language)"&gt;Racket&lt;/a&gt;, que continúan explorando y expandiendo los
principios originales del lenguaje.&lt;/p&gt;</description><category>FunctionalProgramming</category><category>Lisp</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/15-hablemos-de-lisp/</guid><pubDate>Sun, 15 Jun 2025 14:00:00 GMT</pubDate></item><item><title>Reseña de «Hardest problems in mathematics, physics &amp; the future of AI»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/15-hardest-problems-in-mathematics-physics-the-future-of-ai/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En la entrevista "&lt;a href="https://youtu.be/HUkBz-cdB-k"&gt;Hardest problems in mathematics, physics &amp;amp; the future of AI&lt;/a&gt;", Terence Tao comparte sus reflexiones sobre diversos problemas
fundamentales sin resolver en análisis y teoría de números, examina la
metodología de la investigación matemática contemporánea y analiza el
papel emergente que desempeñan la verificación formal y la inteligencia
artificial en la disciplina.&lt;/p&gt;
&lt;h2&gt;Problemas fundamentales y sus complejidades intrínsecas&lt;/h2&gt;
&lt;p&gt;Tao examina varios problemas que se encuentran en la frontera del
conocimiento matemático actual. En análisis, dedica especial atención al
&lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Kakeya_set"&gt;problema de Kakeya&lt;/a&gt;&lt;/strong&gt;, destacando sus profundas conexiones con el
análisis armónico y las ecuaciones en derivadas parciales. Su análisis
revela cómo este problema aparentemente geométrico se entrelaza con
áreas fundamentales del análisis moderno.&lt;/p&gt;
&lt;p&gt;Respecto al &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations"&gt;problema de la regularidad de Navier-Stokes&lt;/a&gt;&lt;/strong&gt;, Tao
identifica la "&lt;a href="https://goong.com/es/word/supercriticality-que-significa--traduccion/"&gt;supercriticalidad&lt;/a&gt;" como el obstáculo central que impide
su resolución. De manera particularmente innovadora, describe
&lt;a href="https://arxiv.org/pdf/1402.0290"&gt;su construcción teórica de un análogo
fluídico de una máquina de von Neumann&lt;/a&gt;, presentándola como una
estrategia prometedora para demostrar la existencia de explosiones en
tiempo finito (&lt;em&gt;blowup&lt;/em&gt;) en las soluciones de estas ecuaciones.&lt;/p&gt;
&lt;h2&gt;Desafíos en teoría de números&lt;/h2&gt;
&lt;p&gt;En el ámbito de la teoría de números, Tao analiza la &lt;strong&gt;&lt;a href="https://es.wikipedia.org/wiki/Conjetura_de_los_n%C3%BAmeros_primos_gemelos"&gt;conjetura de los
primos gemelos&lt;/a&gt;&lt;/strong&gt;, atribuyendo su persistente dificultad a la extrema
fragilidad del patrón subyacente. Explica cómo este patrón podría ser
destruido por "conspiraciones" matemáticas imperceptibles para los
métodos estadísticos tradicionales. Esta fragilidad contrasta
marcadamente con la robustez inherente de las progresiones aritméticas,
como las estudiadas en el &lt;a href="https://en.wikipedia.org/wiki/Green%E2%80%93Tao_theorem"&gt;teorema de Green-Tao&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Un concepto clave que emerge de su análisis es el &lt;a href="https://terrytao.wordpress.com/2007/06/05/open-question-the-parity-problem-in-sieve-theory/"&gt;problema de la
paridad&lt;/a&gt;*, que identifica como un obstáculo metodológico fundamental en
teoría de números. En cuanto a la &lt;a href="https://es.wikipedia.org/wiki/Hip%C3%B3tesis_de_Riemann"&gt;hipótesis de Riemann&lt;/a&gt;, Tao la
considera aún más inaccesible a los métodos actuales, situándola en una
categoría propia de dificultad.&lt;/p&gt;
&lt;h2&gt;Marco filosófico y metodológico&lt;/h2&gt;
&lt;p&gt;Un hilo conductor de la entrevista es la exploración de la &lt;strong&gt;dicotomía
entre estructura y aleatoriedad&lt;/strong&gt;, un tema que permea múltiples áreas de
las matemáticas. Esta perspectiva filosófica informa tanto el análisis
de problemas específicos como la comprensión general de los fenómenos
matemáticos.&lt;/p&gt;
&lt;p&gt;Metodológicamente, Tao defiende un enfoque de &lt;strong&gt;simplificación
estratégica&lt;/strong&gt; en la resolución de problemas. Su estrategia consiste en
descomponer problemas complejos en dificultades individuales, abordar
cada una por separado, y posteriormente integrar las soluciones. Este
método refleja una filosofía pragmática que prioriza la claridad
conceptual y el progreso incremental.&lt;/p&gt;
&lt;h2&gt;Transformación tecnológica de las matemáticas&lt;/h2&gt;
&lt;p&gt;Una porción sustancial de la discusión se centra en el impacto
transformador de la &lt;a href="https://en.wikipedia.org/wiki/Automated_reasoning"&gt;prueba asistida por ordenador&lt;/a&gt;, con particular
énfasis en el asistente de pruebas &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Tao ilustra su potencial a
través de su "&lt;a href="https://teorth.github.io/equational_theories/"&gt;Equational theories project&lt;/a&gt;" de clasificación de 22
millones de identidades algebraicas,
&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;demostrando
cómo estas herramientas facilitan la colaboración a gran escala y la
gestión de la complejidad en pruebas matemáticas modernas&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Sus predicciones sobre el futuro son especialmente significativas:
anticipa que las herramientas de inteligencia artificial &lt;strong&gt;revolucionarán
la formalización matemática&lt;/strong&gt;. Más ambiciosamente, prevé que la IA podría
generar conjeturas matemáticas genuinamente novedosas al identificar
conexiones profundas entre campos aparentemente dispares.&lt;/p&gt;
&lt;h2&gt;Síntesis y perspectiva&lt;/h2&gt;
&lt;p&gt;La entrevista proporciona una ventana excepcional al proceso intelectual
de uno de los matemáticos más influyentes de nuestra época. Tao logra
equilibrar la precisión técnica con la accesibilidad conceptual,
ofreciendo tanto análisis detallados de problemas específicos como
reflexiones más amplias sobre la naturaleza de la investigación
matemática.&lt;/p&gt;
&lt;p&gt;Su visión integra consideraciones técnicas, marcos filosóficos y
prospectivas tecnológicas, presentando una imagen completa de las
matemáticas como disciplina en constante evolución. La entrevista
destaca no solo los desafíos actuales, sino también las herramientas
emergentes que podrían redefinir fundamentalmente cómo se desarrollarán
las matemáticas en el futuro.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/15-hardest-problems-in-mathematics-physics-the-future-of-ai/</guid><pubDate>Sun, 15 Jun 2025 10:00:00 GMT</pubDate></item><item><title>Reseña de «Mathesis: Towards formal theorem proving from natural languages»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural
languages&lt;/a&gt;», se aborda la limitación clave de los demostradores de
teoremas: su dependencia de enunciados ya formalizados. El trabajo se
centra en el paso crítico de la 'autoformalización' —la traducción a un
lenguaje formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;— y presenta Mathesis, un sistema integral
diseñado para automatizar todo el proceso.&lt;/p&gt;
&lt;p&gt;El sistema introduce un Mathesis-Autoformalizer entrenado mediante
aprendizaje por refuerzo para optimizar la traducción a código Lean. Su
rendimiento se evalúa con LeanScorer, y se pone a prueba en
Gaokao-Formal, un nuevo y exigente banco de pruebas. Finalmente,
Mathesis-Prover genera la demostración completa en Lean, asegurando que
la prueba final sea verificable.&lt;/p&gt;
&lt;p&gt;Los resultados demuestran que Mathesis alcanza un rendimiento de
vanguardia en varios bancos de prueba. El análisis revela una conclusión
crucial: las mejoras en la autoformalización impactan el éxito final
mucho más que las mejoras en el demostrador. Esto se explica porque si
el problema se traduce incorrectamente a código Lean, el demostrador
recibe una tarea mal planteada y no puede generar una prueba válida, sin
importar su potencia. El trabajo confirma así que una traducción inicial
de alta calidad es el factor más determinante para el éxito del proceso.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</guid><pubDate>Fri, 13 Jun 2025 16:35:00 GMT</pubDate></item><item><title>Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt;», los autores investigan la aplicabilidad de
los modelos de lenguaje grandes multimodales (MLLMs) al problema de la
demostración automática de teoremas que involucran componentes tanto
textuales como visuales. Motivados por las limitaciones de los enfoques
puramente textuales en dominios como la geometría, donde los diagramas
constituyen información esencial, desarrollan un marco de evaluación
sistemático para esta clase de problemas.&lt;/p&gt;
&lt;p&gt;La contribución principal consiste en la construcción de &lt;a href="https://github.com/Zhitao-He/MATPBench"&gt;MATP-BENCH&lt;/a&gt;, un
conjunto de datos que contiene más de 1000 problemas matemáticos
multimodales formalizados en tres asistentes de demostración: &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Rocq"&gt;Coq&lt;/a&gt; e &lt;a href="https://en.wikipedia.org/wiki/Isabelle_(proof_assistant)"&gt;Isabelle/HOL&lt;/a&gt;. El corpus abarca problemas de complejidad variable,
desde el nivel de secundaria hasta competiciones matemáticas avanzadas,
proporcionando así un banco de pruebas comprehensivo para evaluar
capacidades de razonamiento multimodal.&lt;/p&gt;
&lt;p&gt;Los experimentos incluyen seis modelos representativos: tres con
capacidades especializadas de razonamiento (OpenAI-o1,
Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking) y tres sin estas
capacidades (GPT-4.1, Qwen2.5-VL-Instruct-70B,
Llama3.2-Vision-Instruct-11B). Los resultados revelan que, si bien los
modelos demuestran competencia en la comprensión de problemas y
formalización de enunciados, exhiben deficiencias significativas en la
construcción de cadenas de inferencia válidas.&lt;/p&gt;
&lt;p&gt;El análisis establece que la principal limitación no radica en las
capacidades de percepción visual sino en la insuficiencia del
razonamiento simbólico formal. Los autores concluyen que los MLLMs
actuales no constituyen demostradores automáticos efectivos para
problemas multimodales, identificando la brecha entre comprensión
multimodal y razonamiento lógico como el desafío fundamental a resolver.&lt;/p&gt;
&lt;p&gt;MATP-BENCH se posiciona como el primer banco de prueba estándar para
este dominio, proporcionando una base metodológica para la evaluación de
futuros desarrollos en demostración automática multimodal.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>CoqProver</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>MLLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</guid><pubDate>Fri, 13 Jun 2025 15:10:00 GMT</pubDate></item><item><title>Reseña de 'LeanTutor: A formally-verified AI tutor for mathematical proofs'</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El artículo "&lt;a href="https://arxiv.org/abs/2506.08321"&gt;LeanTutor: A formally-verified AI tutor for mathematical
proofs&lt;/a&gt;" aborda un problema común en la educación matemática: los
estudiantes tienen dificultades para aprender demostraciones.
Actualmente existen dos tipos de herramientas, pero ninguna funciona
bien para enseñar. Los chatbots como ChatGPT son fáciles de usar pero
dan respuestas directas o incorrectas, sin ayudar realmente al
aprendizaje. Los asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; verifican las
matemáticas perfectamente, pero son demasiado complicados para
principiantes. Se necesita una herramienta que combine lo mejor de
ambos: la facilidad del lenguaje natural y la precisión de la
verificación formal.&lt;/p&gt;
&lt;p&gt;Los autores crearon LeanTutor, un sistema que funciona como tutor
inteligente combinando lenguaje natural con verificación formal. El
sistema tiene tres partes que trabajan juntas. Primero, el
'autoformalizador' toma lo que escribe el estudiante en lenguaje normal
y lo convierte a código Lean para verificar si es correcto. Si hay un
error, el 'generador del siguiente paso' calcula cuál sería la respuesta
correcta. Finalmente, el 'generador de retroalimentación' convierte esta
información técnica en consejos útiles para el estudiante, dándole
pistas sin revelar directamente la solución.&lt;/p&gt;
&lt;p&gt;Los investigadores probaron LeanTutor usando un nuevo conjunto de datos
llamado PeanoBench y los resultados fueron positivos. El sistema logró
convertir correctamente la mayoría de los pasos que escribían los
estudiantes y detectó muchos errores. Cuando compararon la
retroalimentación de LeanTutor con otros sistemas, encontraron que era
más precisa y útil para los estudiantes. Los autores concluyen que este
enfoque de combinar IA conversacional con verificación formal es una
buena dirección para crear mejores herramientas educativas.&lt;/p&gt;
&lt;p&gt;Este trabajo presenta una idea muy buena para mejorar la educación
matemática. La principal fortaleza es que logra combinar de manera
inteligente la facilidad de uso del lenguaje natural con la precisión
matemática de Lean. Sin embargo, también tiene algunas limitaciones
importantes. El sistema necesita tener de antemano la solución correcta
del problema, y asume que los pasos del estudiante se pueden traducir
directamente a código Lean, lo que podría no funcionar en situaciones
más complejas. A pesar de estas limitaciones, LeanTutor es un buen
primer paso que muestra cómo la IA puede ayudar a enseñar matemáticas de
forma más efectiva y segura.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>Teaching</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</guid><pubDate>Wed, 11 Jun 2025 17:26:00 GMT</pubDate></item><item><title>El futuro del razonamiento matemático: Integrando IA y Lean</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia "&lt;a href="https://youtu.be/LylJBfvVzyw"&gt;Will computers prove theorems?&lt;/a&gt;", &lt;a href="https://profiles.imperial.ac.uk/k.buzzard"&gt;Kevin Buzzard&lt;/a&gt;
plantea que los ordenadores ya demuestran teoremas, pero la pregunta
crucial es cómo pueden transformar la investigación matemática. Aunque
reconoce la utilidad de las herramientas actuales como las redes
neuronales para identificar patrones, su aplicación permanece
limitada. Los modelos de lenguaje como ChatGPT, por su parte, pueden
ofrecer ideas valiosas, pero fracasan rotundamente en el razonamiento
lógico: tienden a "alucinar" o inventar detalles para parecer
convincentes, lo que los convierte en herramientas poco confiables para
las matemáticas rigurosas.&lt;/p&gt;
&lt;p&gt;La solución que propone Buzzard para superar estas limitaciones radica
en la sinergia entre la inteligencia artificial y los asistentes de
demostración formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Su propuesta consiste en entrenar modelos
de IA para que generen pruebas directamente en código de Lean, en lugar
de utilizar lenguaje natural. De este modo, el asistente de demostración
funciona como un verificador infalible: cualquier argumento lógicamente
incorrecto será rechazado automáticamente por el sistema. Esta
metodología obligaría a la IA a evolucionar desde la mera imitación de
patrones hacia la construcción de razonamientos lógicamente
verificables.&lt;/p&gt;
&lt;p&gt;No obstante, el principal obstáculo para materializar esta visión es la
escasez de matemáticas modernas y avanzadas formalizadas en Lean,
elementos esenciales para el entrenamiento de estos modelos. Buzzard
concluye con un llamamiento directo a la comunidad matemática: considera
que es responsabilidad de los investigadores emprender la tarea
fundamental de formalizar el conocimiento de sus respectivos campos, tal
como él mismo está haciendo con el &lt;a href="https://imperialcollegelondon.github.io/FLT/"&gt;último teorema de Fermat&lt;/a&gt;. Argumenta
que este esfuerzo resulta crucial para desarrollar las herramientas que
revolucionarán la disciplina, a pesar de que el sistema académico actual
no reconozca ni recompense adecuadamente este tipo de contribuciones.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</guid><pubDate>Wed, 11 Jun 2025 15:26:00 GMT</pubDate></item><item><title>El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Hoy, en su conferencia "&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project&lt;/a&gt;", &lt;a href="https://en.wikipedia.org/wiki/Terence_Tao"&gt;Terence Tao&lt;/a&gt;
defendió que la investigación matemática debe evolucionar hacia un
modelo colaborativo a gran escala, semejante al empleado en otras
disciplinas científicas. Esta transformación requiere el uso de
herramientas modernas como plataformas colaborativas (&lt;a href="https://github.com/teorth/equational_theories"&gt;GitHub&lt;/a&gt;),
asistentes de prueba formales (&lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;) y automatización mediante
inteligencia artificial. El proyecto &lt;a href="https://teorth.github.io/equational_theories/"&gt;ETP (Equational Theories Project)&lt;/a&gt;
constituye un ejemplo paradigmático de esta nueva aproximación a la
investigación matemática.&lt;/p&gt;
&lt;p&gt;El proyecto nació de una pregunta aparentemente simple planteada en el
foro MathOverflow, pero pronto adquirió una dimensión extraordinaria:
mapear completamente el "gráfico de implicaciones" entre 4,692 leyes
algebraicas únicas dentro de estructuras elementales denominadas
magmas. Esta ambiciosa meta implicaba resolver más de 22 millones de
problemas individuales, donde cada par de leyes requería encontrar una
prueba de implicación o desarrollar un contraejemplo que la refutara. La
magnitud descomunal de este desafío lo convertía en una tarea imposible
de abordar mediante los métodos tradicionales de investigación
individual o de pequeños equipos.&lt;/p&gt;
&lt;p&gt;La estrategia implementada por el ETP consistió en un flujo de trabajo
híbrido y descentralizado de notable innovación. La componente humana
aprovechó la creatividad de una extensa comunidad de colaboradores para
desarrollar pruebas y contraejemplos ingeniosos, mientras que la
componente computacional empleó masivamente probadores automáticos de
teoremas (ATPs) y otras herramientas para resolver millones de casos más
directos. El elemento fundamental que garantizó la integridad del
proyecto fue la formalización exhaustiva de cada resultado en el
asistente de pruebas Lean, asegurando una corrección absoluta y creando
una base de conocimiento completamente verificada y confiable.&lt;/p&gt;
&lt;p&gt;En el plazo extraordinariamente breve de tres meses, el proyecto logró
resolver prácticamente la totalidad de los 22 millones de problemas
planteados. Además, el proceso de abordar los casos más complejos
estimuló el desarrollo de técnicas matemáticas innovadoras, culminando
con la formulación de un nuevo y fascinante problema abierto. El ETP
demostró que este modelo colaborativo trasciende la mera verificación de
conocimiento existente para convertirse en un motor poderoso de
descubrimiento matemático, estableciendo así un precedente exitoso para
una investigación matemática más abierta, transparente y asistida
computacionalmente.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</guid><pubDate>Tue, 10 Jun 2025 18:00:00 GMT</pubDate></item><item><title>El futuro de las matemáticas - Descubrimiento colaborativo entre humanos y máquinas</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Ayer, en su conferencia "&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative
discovery&lt;/a&gt;", &lt;a href="https://www.cl.cam.ac.uk/~mj201/"&gt;Mateja Jamnik&lt;/a&gt; presentó una visión de la inteligencia
artificial no como una simple herramienta para resolver problemas, sino
como un socio colaborativo en el descubrimiento matemático. Su trabajo
explora cómo las máquinas pueden proponer ideas y acelerar la
investigación. A través de un estudio empírico con matemáticos, demostró
que la interacción humano-IA es compleja; una respuesta de la IA no
necesita ser perfectamente correcta para ser útil, ya que incluso ideas
parcialmente erróneas pueden inspirar nuevas vías de pensamiento,
mientras que respuestas correctas pero verbosas pueden resultar
inútiles.&lt;/p&gt;
&lt;p&gt;El núcleo técnico de su propuesta, materializado en trabajos como su
artículo "&lt;a href="https://openreview.net/pdf?id=SMa9EAovKMC"&gt;Draft, sketch, and prove: Guiding formal theorem provers with
informal proofs&lt;/a&gt;", es un ciclo auto-mejorable que integra el vasto
conocimiento matemático informal. A través de la arquitectura ‘Borrador,
Esquema y Prueba’ descrita en dicho artículo, la IA traduce pruebas
humanas a un formato formal y riguroso. Este ciclo culmina en un sistema
‘conjeturador-demostrador’ que genera progresivamente nuevas conjeturas,
las evalúa según su capacidad para ayudar a resolver problemas más
difíciles y utiliza las mejores para mejorar continuamente, acercándose
así a la resolución de teoremas que antes eran inaccesibles.&lt;/p&gt;
&lt;p&gt;El objetivo final es integrar plenamente al ser humano en este ciclo de
descubrimiento. Jamnik imagina un futuro donde los matemáticos
interactúen con este sistema para proponer y evaluar conjeturas, guiando
la dirección de la investigación. Su conclusión es que la IA no
reemplazará a los matemáticos, sino que los potenciará, creando una
sinergia entre la intuición humana y la capacidad de la máquina. &lt;strong&gt;El
futuro de las matemáticas, según su visión, es una era de descubrimiento
colaborativo entre humanos y máquinas.&lt;/strong&gt;&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</guid><pubDate>Tue, 10 Jun 2025 17:00:00 GMT</pubDate></item><item><title>AlphaProof - Aprendizaje por refuerzo aplicado a la demostración matemática</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia de ayer "&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;",
Thomas Hubert de Google DeepMind presentó &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;AlphaProof&lt;/a&gt;, un sistema de
inteligencia artificial que aplica los principios del &lt;a href="https://en.wikipedia.org/wiki/Reinforcement_learning"&gt;aprendizaje por
refuerzo&lt;/a&gt; (RL, del inglés "&lt;em&gt;Reinforcement learning&lt;/em&gt;") al dominio de las
matemáticas formales. El concepto fundamental radica en que los
asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; proporcionan el entorno perfecto
para el RL: un espacio de experimentación masiva con retroalimentación
inequívoca (una prueba matemática es correcta o incorrecta, sin
ambigüedades). Siguiendo el paradigma exitoso de sistemas como AlphaGo
Zero, AlphaProof está diseñado para generar conocimiento matemático de
forma autónoma, trascendiendo la mera imitación de demostraciones
humanas preexistentes.&lt;/p&gt;
&lt;p&gt;La arquitectura de AlphaProof se estructura en un proceso de múltiples
fases que combina diferentes técnicas de aprendizaje
automático. Inicialmente, emplea modelos de lenguaje para autoformalizar
problemas matemáticos expresados en lenguaje natural hacia el código
formal de Lean, generando así un extenso conjunto de datos de
entrenamiento. Su modelo demostrador experimenta dos etapas: primero, un
entrenamiento supervisado utilizando la biblioteca &lt;a href="https://leanprover-community.github.io/mathlib-overview.html"&gt;mathlib&lt;/a&gt;, seguido de
un refinamiento intensivo mediante RL que resuelve millones de problemas
matemáticos. Para desafíos particularmente complejos —como los de la
Olimpiada Internacional de Matemáticas (IMO)—, el sistema implementa una
estrategia de adaptación en tiempo real, generando y resolviendo
múltiples variantes de un problema para desarrollar gradualmente la
intuición necesaria.&lt;/p&gt;
&lt;p&gt;Los resultados validan el potencial transformador de AlphaProof como
herramienta matemática colaborativa. El sistema alcanzó una puntuación
equivalente a una &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;medalla de plata en la IMO&lt;/a&gt; y, durante una demostración
en vivo durante la conferencia, asistió exitosamente a un matemático a
completar los pasos de una prueba compleja relacionada con la función
zeta de Riemann. Hubert enfatiza que el objetivo trasciende las
competiciones académicas: la meta fundamental es contribuir
significativamente a la investigación matemática contemporánea,
convirtiendo AlphaProof en una útil para la comunidad matemática que
facilite el descubrimiento y verificación de nuevas verdades
matemáticas.&lt;/p&gt;</description><category>AI</category><category>AlphaProof</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>RL</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</guid><pubDate>Tue, 10 Jun 2025 11:50:00 GMT</pubDate></item><item><title>AutoGPS - Un sistema neuro-simbólico para la geometría</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El artículo &lt;a href="https://arxiv.org/pdf/2505.23381"&gt;AutoGPS: Automated Geometry Problem Solving via Multimodal
Formalization and Deductive Reasoning&lt;/a&gt;
presenta &lt;a href="https://jayce-ping.github.io/AutoGPS-homepage/"&gt;AutoGPS&lt;/a&gt;, un
sistema paradigmático para la geometría. Este trabajo aborda la
dicotomía fundamental entre los modelos neuronales, que destacan en la
interpretación multimodal pero carecen de fiabilidad lógica, y los
métodos simbólicos, que garantizan el rigor pero son ineficaces para
formalizar problemas a partir de entradas complejas. AutoGPS resuelve
este dilema mediante un marco neuro-simbólico: un &lt;strong&gt;formalizador de
problemas multimodales&lt;/strong&gt; (MPF) traduce la entrada visual y textual a un
lenguaje lógico, sobre el cual opera un &lt;strong&gt;razonador simbólico
deductivo&lt;/strong&gt; (DSR) para derivar la solución.&lt;/p&gt;
&lt;p&gt;La innovación crucial reside en la interacción bidireccional entre ambos
componentes. El DSR no se limita a resolver el problema formalizado,
sino que actúa como un verificador, validando la interpretación del MPF
y pudiendo solicitarle correcciones. Este bucle de retroalimentación
garantiza la consistencia lógica de todo el proceso, fusionando la
capacidad heurística del modelo neuronal con el rigor inflexible del
razonamiento deductivo.&lt;/p&gt;
&lt;p&gt;Como resultado, AutoGPS establece un nuevo estado del arte en los
benchmarks de referencia, produciendo derivaciones que no solo son
correctas, sino también concisas y legibles para un humano. De este
modo, redefine el estándar de fiabilidad e interpretabilidad en la
resolución automática de problemas matemáticos. La &lt;a href="https://jayce-ping.github.io/AutoGPS-homepage/"&gt;página del proyecto&lt;/a&gt;
ofrece ejemplos ilustrativos de su funcionamiento.&lt;/p&gt;</description><category>AI</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/</guid><pubDate>Sun, 08 Jun 2025 03:00:00 GMT</pubDate></item></channel></rss>