<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium (Publicaciones sobre Reseña)</title><link>https://jaalonso.github.io/vestigium/</link><description></description><atom:link href="https://jaalonso.github.io/vestigium/categories/cat_resena.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sun, 08 Jun 2025 09:05:50 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Más allá de la "ilusión de pensar"</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Un reciente artículo de investigadores de Apple, titulado
"&lt;a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf"&gt;The illusion of thinking: A survey of the state of the art in Large Language Models&lt;/a&gt;",
postula que las impresionantes capacidades de los Grandes Modelos de
Lenguaje (LLMs) no derivan de una comprensión o razonamiento genuino,
sino de una sofisticada imitación de patrones estadísticos extraídos de
vastos corpus de datos. Esta "ilusión de pensar" se vuelve
particularmente manifiesta en dominios que exigen una lógica estricta y
verificable, como las matemáticas formales. En este campo, la propensión
de los LLMs a la "alucinación" y su inherente falta de un modelo causal
del mundo limitan fundamentalmente su fiabilidad, incapacitándolos para
producir razonamientos complejos de manera autónoma y garantizada.&lt;/p&gt;
&lt;p&gt;Para abordar esta limitación estructural, la investigación contemporánea
ha centrado sus esfuerzos en el desarrollo de arquitecturas híbridas
neuro-simbólicas. Dichos sistemas implementan una división funcional del
trabajo computacional: el componente neuronal (el LLM) opera como
interfaz de alto nivel, encargado de procesar entradas en lenguaje
natural y generar estrategias heurísticas preliminares. Estas propuestas
son luego transferidas a un módulo simbólico —ya sea un sistema de
cálculo algebraico exacto o un demostrador de teoremas— que actúa como
verificador formal. Este último componente, regido por reglas lógicas
inflexibles, examina cada inferencia producida por el LLM,
proporcionando retroalimentación inmediata y garantizando la corrección
deductiva del proceso.&lt;/p&gt;
&lt;p&gt;La eficacia de este paradigma ha sido demostrada empíricamente por
sistemas de última generación diseñados para resolver problemas de la
Olimpiada Internacional de Matemáticas (IMO). Tal como se documenta en
el estudio &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;AI achieves silver-medal standard solving International
Mathematical Olympiad problems&lt;/a&gt;, estas plataformas combinan un LLM encargado de la generación inicial de hipótesis con herramientas
especializadas como AlphaProof, un sistema optimizado para demostrar
enunciados matemáticos en el lenguaje formal de &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Cabe destacar que Lean, lejos de ser una mera herramienta auxiliar, constituye un
componente estructural en estos sistemas: su integración permite
traducir la capacidad heurística de los LLMs a un marco verificable
formalmente. Esta sinergia entre la creatividad inductiva de los modelos
neuronales y el rigor de los sistemas simbólicos representa el estado
del arte en la construcción de inteligencias artificiales capaces de
razonamiento matemático formalmente validable.&lt;/p&gt;</description><category>ITP</category><category>LeanProver</category><category>LLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/</guid><pubDate>Sun, 08 Jun 2025 03:00:00 GMT</pubDate></item></channel></rss>