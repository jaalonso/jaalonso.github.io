<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium (Publicaciones sobre LLMs)</title><link>https://jaalonso.github.io/vestigium/</link><description></description><atom:link href="https://jaalonso.github.io/vestigium/categories/llms.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 14 Jun 2025 09:16:14 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Readings shared June 13, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 13 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2503.00959"&gt;Formalizing zeta and L-functions in Lean&lt;/a&gt;. ~ David Loeffler, Michael Stoll. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="http://adam.chlipala.net/theses/teshome.pdf"&gt;Formal verification of relational algebra transformations in Fiat2 using Coq&lt;/a&gt;. ~ Christian Teshome. #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10048"&gt;Growing a modular framework for modal systems - HOLMS: a HOL Light library&lt;/a&gt;. ~ Antonella Bilotta. #ITP #HOL&lt;sub&gt;Light&lt;/sub&gt; #Logic #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.morph.so/blog/trinity"&gt;Trinity: an autoformalization system for verified superintelligence&lt;/a&gt;. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/morph-labs/lean-abc-true-almost-always"&gt;The abc conjecture almost always — autoformalized&lt;/a&gt;. ~ Jesse Michael Han et als. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt; ~ Zhitao He et als. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural languages&lt;/a&gt;. ~ Yu Xuejun et als. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10558"&gt;StepProof: Step-by-step verification of natural language mathematical proofs&lt;/a&gt;. ~ Xiaolin Hu, Qinghua Zhou, Bogdan Grechuk, Ivan Y. Tyukin. #LLMs #ITP #IsabelleHOL #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/"&gt;Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»&lt;/a&gt;. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/"&gt;Reseña de «Mathesis: Towards formal theorem proving from natural languages»&lt;/a&gt;. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>Autoformalization</category><category>CoqProver</category><category>HOL&lt;sub&gt;Light&lt;/sub&gt;</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>MLLMs</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</guid><pubDate>Sat, 14 Jun 2025 09:15:00 GMT</pubDate></item><item><title>Reseña de «Mathesis: Towards formal theorem proving from natural languages»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural
languages&lt;/a&gt;», se aborda la limitación clave de los demostradores de
teoremas: su dependencia de enunciados ya formalizados. El trabajo se
centra en el paso crítico de la 'autoformalización' —la traducción a un
lenguaje formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;— y presenta Mathesis, un sistema integral
diseñado para automatizar todo el proceso.&lt;/p&gt;
&lt;p&gt;El sistema introduce un Mathesis-Autoformalizer entrenado mediante
aprendizaje por refuerzo para optimizar la traducción a código Lean. Su
rendimiento se evalúa con LeanScorer, y se pone a prueba en
Gaokao-Formal, un nuevo y exigente banco de pruebas. Finalmente,
Mathesis-Prover genera la demostración completa en Lean, asegurando que
la prueba final sea verificable.&lt;/p&gt;
&lt;p&gt;Los resultados demuestran que Mathesis alcanza un rendimiento de
vanguardia en varios bancos de prueba. El análisis revela una conclusión
crucial: las mejoras en la autoformalización impactan el éxito final
mucho más que las mejoras en el demostrador. Esto se explica porque si
el problema se traduce incorrectamente a código Lean, el demostrador
recibe una tarea mal planteada y no puede generar una prueba válida, sin
importar su potencia. El trabajo confirma así que una traducción inicial
de alta calidad es el factor más determinante para el éxito del proceso.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</guid><pubDate>Fri, 13 Jun 2025 16:35:00 GMT</pubDate></item><item><title>Readings shared June 12, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 12 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/R2t9ZRWiWEk"&gt;Formalizing the divided power envelope in Lean&lt;/a&gt;. ~ María Inés de Frutos Fernández. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/YtbfIjgzNDI"&gt;Lean meta-theory: The proofs behind the proofs&lt;/a&gt;. ~ Mario Carneiro. #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/litexlang/golitex"&gt;Litex: Scale formal reasoning in AI age&lt;/a&gt;. ~ Jiachen Shen. #Logic #ATP #LitexLang&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neus-2025.github.io/files/papers/paper_33.pdf"&gt;Lean Copilot: Large language models as copilots for theorem proving in Lean&lt;/a&gt;. ~ Peiyang Song, Kaiyu Yang, Anima Anandkumar. #ITP #LeanProver #LLMs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3713082.3730382"&gt;Can large language models verify system software? A case study using FSCQ as a benchmark&lt;/a&gt;. ~ Jianxing Qin et als. #LLMs #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muratkasimov.art/Ya/Articles/Reinventing-records-and-variants"&gt;Reinventing records and variants&lt;/a&gt;. ~ Murat Kasimov. #Haskell #FunctionalProgramming&lt;/li&gt;
&lt;/ul&gt;</description><category>ATP</category><category>CoqProver</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</guid><pubDate>Fri, 13 Jun 2025 08:40:00 GMT</pubDate></item><item><title>Readings shared June 10, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 10 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lawrencecpaulson.github.io//2025/06/09/Inductive_Definitions.html"&gt;Inductive definitions&lt;/a&gt;. ~ Lawrence Paulson. #ITP #IsabelleHOL #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project: advancing collaborative mathematical research at scale&lt;/a&gt;. ~ Terence Tao et als. #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathscholar.org/2025/06/new-ai-stuns-mathematicians-with-its-problem-solving-skill/"&gt;New AI stuns mathematicians with its problem-solving skill&lt;/a&gt;. ~ David H Bailey. #AI #LLMs #Math #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07477"&gt;Premise selection for a Lean hammer&lt;/a&gt;. ~ Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck. #ITP #LeanProver #AI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04592v1"&gt;Safe: Enhancing mathematical reasoning in large language models via retrospective step-aware formal verification&lt;/a&gt;. ~ Chengwu Liu et als. #LLMs #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;. ~ Thomas Hubert. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative discovery&lt;/a&gt;. ~ Mateja Jamnik. #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04575v1"&gt;Are LLMs reliable translators of logical reasoning across lexically diversified contexts?&lt;/a&gt; ~ Qingchuan Li et als. #LLMs #Math #ATP #Prover9&lt;/li&gt;
&lt;li&gt;&lt;a href="https://coyotetracks.org/blog/dr-neckbeard-emacs/"&gt;Dr. Neckbeard, or how I learned to stop worrying and love Emacs&lt;/a&gt;. ~ Watts Martin. #Emacs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bib.us.es/sites/bib3.us.es/files/investiga52.pdf"&gt;Revistas, editoriales y congresos depredadores&lt;/a&gt;. #Investigación&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/"&gt;AlphaProof: Aprendizaje por refuerzo aplicado a la demostración matemática&lt;/a&gt;. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/"&gt;El futuro de las matemáticas: Descubrimiento colaborativo entre humanos y máquinas&lt;/a&gt;. #AIforMath #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/"&gt;El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)&lt;/a&gt;. #AIforMath #ITP #LeanProver #Math&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>AlphaProof</category><category>ATP</category><category>Emacs</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Prover9</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</guid><pubDate>Wed, 11 Jun 2025 09:06:00 GMT</pubDate></item><item><title>Readings shared June 9, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 9 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://emilyriehl.github.io/files/invisible.pdf"&gt;Formalizing invisible mathematics: case studies from higher category theory&lt;/a&gt;. ~ Emily Riehl. #ITP #LeanProver #Math #CategoryTheory&lt;/li&gt;
&lt;li&gt;&lt;a href="https://provables.github.io/sequencelib/"&gt;Sequencelib: A platform for formalizing in Lean 4 sequences from "The On-Line Encyclopedia of Integer Sequences" (OEIS)&lt;/a&gt;. ~ Walter Moreira, Joe Stubbs. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.scientificamerican.com/article/inside-the-secret-meeting-where-mathematicians-struggled-to-outsmart-ai/"&gt;At secret math meeting, researchers struggle to outsmart AI&lt;/a&gt;. ~ Lyndie Chiou. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mmhaskell.com/blog/2025/6/9/spatial-reasoning-with-zigzag-patterns"&gt;Comparing code: Spatial reasoning with zigzag patterns! ~ James Bowen&lt;/a&gt;. #Haskell #FunctionalProgramming #Rust&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@kenichisasagawa/exploring-topological-spaces-with-prolog-a-practical-approach-using-mathematics-with-prolog-b5806bb8b98f"&gt;Exploring topological spaces with Prolog: A practical approach using "Mathematics with Prolog"&lt;/a&gt;. ~ Kenichi Sasagawa. #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2108.09893"&gt;Teaching and learning mathematics with Prolog&lt;/a&gt;. ~ Tom Bensky (2021). #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/09-evaluando-la-ia-con-problemas-matematicos-ineditos-de-nivel-experto/"&gt;Evaluando la IA con problemas matemáticos inéditos de nivel experto&lt;/a&gt;. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/li-12"&gt;Curso "Lógica informática (2012-13)"&lt;/a&gt;. #Lógica #ProgramaciónLógica #Prolog&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/lmf-12"&gt;Curso "Lógica matemática y fundamentos (2012-13)"&lt;/a&gt;. #Lógica #Haskell #ProgramaciónFuncional #Isabelle/HOL&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>CategoryTheory</category><category>FunctionalProgramming</category><category>Haskell</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>LogicProgramming</category><category>Math</category><category>Prolog</category><category>Rust</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</guid><pubDate>Tue, 10 Jun 2025 04:00:00 GMT</pubDate></item><item><title>Readings shared June 8, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 8 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf"&gt;The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity&lt;/a&gt;. ~ Parshin Shojaee et als. #LLMs #Reasoning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/"&gt;Más allá de la "ilusión de pensar"&lt;/a&gt;. #LLMs #Reasoning #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/"&gt;AutoGPS: Un sistema neuro-simbólico para la geometría&lt;/a&gt;. #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/i1m-12"&gt;Curso "Informática (2012-13)"&lt;/a&gt;. #Haskell #ProgramaciónFuncional #Algorítmica #CálculoSimbólico #Maxima&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>Algorithms</category><category>CAS</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Maxima</category><category>Reasoning</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</guid><pubDate>Sun, 08 Jun 2025 04:00:00 GMT</pubDate></item><item><title>Más allá de la "ilusión de pensar"</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Un reciente artículo de investigadores de Apple, titulado
"&lt;a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf"&gt;The illusion of thinking: A survey of the state of the art in Large Language Models&lt;/a&gt;",
postula que las impresionantes capacidades de los Grandes Modelos de
Lenguaje (LLMs) no derivan de una comprensión o razonamiento genuino,
sino de una sofisticada imitación de patrones estadísticos extraídos de
vastos corpus de datos. Esta "ilusión de pensar" se vuelve
particularmente manifiesta en dominios que exigen una lógica estricta y
verificable, como las matemáticas formales. En este campo, la propensión
de los LLMs a la "alucinación" y su inherente falta de un modelo causal
del mundo limitan fundamentalmente su fiabilidad, incapacitándolos para
producir razonamientos complejos de manera autónoma y garantizada.&lt;/p&gt;
&lt;p&gt;Para abordar esta limitación estructural, la investigación contemporánea
ha centrado sus esfuerzos en el desarrollo de arquitecturas híbridas
neuro-simbólicas. Dichos sistemas implementan una división funcional del
trabajo computacional: el componente neuronal (el LLM) opera como
interfaz de alto nivel, encargado de procesar entradas en lenguaje
natural y generar estrategias heurísticas preliminares. Estas propuestas
son luego transferidas a un módulo simbólico —ya sea un sistema de
cálculo algebraico exacto o un demostrador de teoremas— que actúa como
verificador formal. Este último componente, regido por reglas lógicas
inflexibles, examina cada inferencia producida por el LLM,
proporcionando retroalimentación inmediata y garantizando la corrección
deductiva del proceso.&lt;/p&gt;
&lt;p&gt;La eficacia de este paradigma ha sido demostrada empíricamente por
sistemas de última generación diseñados para resolver problemas de la
Olimpiada Internacional de Matemáticas (IMO). Tal como se documenta en
el estudio &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;AI achieves silver-medal standard solving International
Mathematical Olympiad problems&lt;/a&gt;, estas plataformas combinan un LLM encargado de la generación inicial de hipótesis con herramientas
especializadas como AlphaProof, un sistema optimizado para demostrar
enunciados matemáticos en el lenguaje formal de &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Cabe destacar que Lean, lejos de ser una mera herramienta auxiliar, constituye un
componente estructural en estos sistemas: su integración permite
traducir la capacidad heurística de los LLMs a un marco verificable
formalmente. Esta sinergia entre la creatividad inductiva de los modelos
neuronales y el rigor de los sistemas simbólicos representa el estado
del arte en la construcción de inteligencias artificiales capaces de
razonamiento matemático formalmente validable.&lt;/p&gt;</description><category>ITP</category><category>LeanProver</category><category>LLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/</guid><pubDate>Sun, 08 Jun 2025 03:00:00 GMT</pubDate></item><item><title>Readings shared May 23, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/05/23-readings_shared_05-23-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 23 May 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2505.16963"&gt;A formal proof of complexity bounds on diophantine equations&lt;/a&gt;. ~ Jonas Bayer, Marco David. #ITP #IsabelleHOL #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tildeweb.au.dk/au571806/publications/files/2025-fscd-guarded-dom.pdf"&gt;Solving guarded domain equations in presheaves over ordinals and mechanizing it&lt;/a&gt;. ~ Sergei Stepanenko, Amin Timany. #ITP #RocqProver #CategoryTheory&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2505.12680"&gt;Ineq-Comp: Benchmarking human-intuitive compositional reasoning in automated theorem proving on inequalities&lt;/a&gt;. ~ Haoyu Zhao et als. #LLMs #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2505.13938v2"&gt;CLEVER: A curated benchmark for formally verified code generation&lt;/a&gt;. ~ Amitayush Thakur et als. #LLMs #ITP #LeanProver #AIforCode&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.eng.unimelb.edu.au/rizkallahc/theses/minh-do-undergrad-project-report.pdf"&gt;Formalisation of fairness notions in assignment problem&lt;/a&gt;. ~ Duc Minh Do. #ITP #IsabelleHOL&lt;/li&gt;
&lt;/ul&gt;</description><category>AIforCode</category><category>CategoryTheory</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>RocqProver</category><guid>https://jaalonso.github.io/vestigium/posts/2025/05/23-readings_shared_05-23-25/</guid><pubDate>Fri, 23 May 2025 04:00:00 GMT</pubDate></item><item><title>Readings shared May 21, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/05/21-readings_shared_05-21-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 21 May 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://youtu.be/LylJBfvVzyw"&gt;Will computers prove theorems?&lt;/a&gt; ~ Kevin Buzzard. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://youtu.be/aF7IIWfXh3A"&gt;Formalizing the future: Lean’s impact on mathematics, programming, and AI&lt;/a&gt;. ~ Leo De Moura. #ITP #LeanProver #Math #CompSci #AI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ankitku.github.io/stuff/floodsub-acl2ws.pdf"&gt;A formalization of the correctness of the Floodsub protocol&lt;/a&gt;. ~ Ankit Kumar, Panagiotis Manolios. #ITP #ACL2&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/codelion/openevolve"&gt;OpenEvolve: Open-source implementation of AlphaEvolve&lt;/a&gt;. ~ Asankhaya Sharma. #AI #LLMs #AlphaEvolve #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/PhialsBasement/AlphaEvolve-MatrixMul-Verification"&gt;AlphaEvolveVerify: Verification of Google DeepMind's AlphaEvolve 48-multiplication matrix algorithm&lt;/a&gt;. ~ Deming Xu. #Python #Programming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://youtu.be/of92m4XNgrM"&gt;Toward safe, flexible, and efficient software in Common Lisp&lt;/a&gt;. ~ Robert Smith. #CommonLisp&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.researchgate.net/publication/391802524_Theorems_and_Conjectures_with_Python"&gt;Theorems and conjectures with Python&lt;/a&gt;. ~ Alessio Drivet. #Math #Python #Programming&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.researchgate.net/publication/391837654_Analysis_of_selection_noise_in_genetic_algorithms"&gt;Analysis of selection noise in genetic algorithms&lt;/a&gt;. Nataliya M. Gulayeva, Joaquín Borrego-Díaz, Fernando Sancho-Caparrini. #GeneticAlgoritm&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gitlab.com/purlupar/org-expex"&gt;org-expex: Expex glosses in Org-mode (Emacs org-mode extension to auto-create linguistic glosses)&lt;/a&gt;. ~ David Diem. #Emacs #OrgMode&lt;/li&gt;
&lt;/ul&gt;</description><category>ACL2</category><category>AI</category><category>AlphaEvolve</category><category>CommonLisp</category><category>CompSci</category><category>Emacs</category><category>GeneticAlgoritm</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>OrgMode</category><category>Programming</category><category>Python</category><guid>https://jaalonso.github.io/vestigium/posts/2025/05/21-readings_shared_05-21-25/</guid><pubDate>Wed, 21 May 2025 04:00:00 GMT</pubDate></item><item><title>Readings shared May 16, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/05/16-readings_shared_05-16-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 16 May 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/"&gt;AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms&lt;/a&gt;. ~ AlphaEvolve team. #AI #LLMs #AlphaEvolve #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf"&gt;AlphaEvolve: A coding agent for scientific and algorithmic discovery&lt;/a&gt;. ~ AlphaEvolve team. #AI #LLMs #AlphaEvolve #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://cacm.acm.org/news/the-collapse-of-gpt/"&gt;The collapse of GPT (Will future artificial intelligence systems perform increasingly poorly due to AI-generated material in their training data?)&lt;/a&gt;. ~ Neil Savage. #AI #GPT&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.genbeta.com/inteligencia-artificial/google-presenta-ia-capaz-mejorarse-a-esta-batiendo-a-grandes-matematicos-humanos"&gt;La última IA de Google promete ser capaz de mejorarse a sí misma&lt;/a&gt;. De momento, ya está superando a los matemáticos humanos. ~ Marcos Merino. #AI #LLMs #AlphaEvolve #Math&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AlphaEvolve</category><category>GPT</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/05/16-readings_shared_05-16-25/</guid><pubDate>Fri, 16 May 2025 04:00:00 GMT</pubDate></item></channel></rss>