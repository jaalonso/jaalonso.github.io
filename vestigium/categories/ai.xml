<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium (Publicaciones sobre AI)</title><link>https://jaalonso.github.io/vestigium/</link><description></description><atom:link href="https://jaalonso.github.io/vestigium/categories/ai.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 14 Jun 2025 09:16:14 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Readings shared June 13, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 13 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2503.00959"&gt;Formalizing zeta and L-functions in Lean&lt;/a&gt;. ~ David Loeffler, Michael Stoll. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="http://adam.chlipala.net/theses/teshome.pdf"&gt;Formal verification of relational algebra transformations in Fiat2 using Coq&lt;/a&gt;. ~ Christian Teshome. #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10048"&gt;Growing a modular framework for modal systems - HOLMS: a HOL Light library&lt;/a&gt;. ~ Antonella Bilotta. #ITP #HOL&lt;sub&gt;Light&lt;/sub&gt; #Logic #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.morph.so/blog/trinity"&gt;Trinity: an autoformalization system for verified superintelligence&lt;/a&gt;. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/morph-labs/lean-abc-true-almost-always"&gt;The abc conjecture almost always — autoformalized&lt;/a&gt;. ~ Jesse Michael Han et als. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt; ~ Zhitao He et als. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural languages&lt;/a&gt;. ~ Yu Xuejun et als. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10558"&gt;StepProof: Step-by-step verification of natural language mathematical proofs&lt;/a&gt;. ~ Xiaolin Hu, Qinghua Zhou, Bogdan Grechuk, Ivan Y. Tyukin. #LLMs #ITP #IsabelleHOL #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/"&gt;Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»&lt;/a&gt;. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/"&gt;Reseña de «Mathesis: Towards formal theorem proving from natural languages»&lt;/a&gt;. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>Autoformalization</category><category>CoqProver</category><category>HOL&lt;sub&gt;Light&lt;/sub&gt;</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>MLLMs</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</guid><pubDate>Sat, 14 Jun 2025 09:15:00 GMT</pubDate></item><item><title>Reseña de «Mathesis: Towards formal theorem proving from natural languages»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural
languages&lt;/a&gt;», se aborda la limitación clave de los demostradores de
teoremas: su dependencia de enunciados ya formalizados. El trabajo se
centra en el paso crítico de la 'autoformalización' —la traducción a un
lenguaje formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;— y presenta Mathesis, un sistema integral
diseñado para automatizar todo el proceso.&lt;/p&gt;
&lt;p&gt;El sistema introduce un Mathesis-Autoformalizer entrenado mediante
aprendizaje por refuerzo para optimizar la traducción a código Lean. Su
rendimiento se evalúa con LeanScorer, y se pone a prueba en
Gaokao-Formal, un nuevo y exigente banco de pruebas. Finalmente,
Mathesis-Prover genera la demostración completa en Lean, asegurando que
la prueba final sea verificable.&lt;/p&gt;
&lt;p&gt;Los resultados demuestran que Mathesis alcanza un rendimiento de
vanguardia en varios bancos de prueba. El análisis revela una conclusión
crucial: las mejoras en la autoformalización impactan el éxito final
mucho más que las mejoras en el demostrador. Esto se explica porque si
el problema se traduce incorrectamente a código Lean, el demostrador
recibe una tarea mal planteada y no puede generar una prueba válida, sin
importar su potencia. El trabajo confirma así que una traducción inicial
de alta calidad es el factor más determinante para el éxito del proceso.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</guid><pubDate>Fri, 13 Jun 2025 16:35:00 GMT</pubDate></item><item><title>Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt;», los autores investigan la aplicabilidad de
los modelos de lenguaje grandes multimodales (MLLMs) al problema de la
demostración automática de teoremas que involucran componentes tanto
textuales como visuales. Motivados por las limitaciones de los enfoques
puramente textuales en dominios como la geometría, donde los diagramas
constituyen información esencial, desarrollan un marco de evaluación
sistemático para esta clase de problemas.&lt;/p&gt;
&lt;p&gt;La contribución principal consiste en la construcción de &lt;a href="https://github.com/Zhitao-He/MATPBench"&gt;MATP-BENCH&lt;/a&gt;, un
conjunto de datos que contiene más de 1000 problemas matemáticos
multimodales formalizados en tres asistentes de demostración: &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Rocq"&gt;Coq&lt;/a&gt; e &lt;a href="https://en.wikipedia.org/wiki/Isabelle_(proof_assistant)"&gt;Isabelle/HOL&lt;/a&gt;. El corpus abarca problemas de complejidad variable,
desde el nivel de secundaria hasta competiciones matemáticas avanzadas,
proporcionando así un banco de pruebas comprehensivo para evaluar
capacidades de razonamiento multimodal.&lt;/p&gt;
&lt;p&gt;Los experimentos incluyen seis modelos representativos: tres con
capacidades especializadas de razonamiento (OpenAI-o1,
Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking) y tres sin estas
capacidades (GPT-4.1, Qwen2.5-VL-Instruct-70B,
Llama3.2-Vision-Instruct-11B). Los resultados revelan que, si bien los
modelos demuestran competencia en la comprensión de problemas y
formalización de enunciados, exhiben deficiencias significativas en la
construcción de cadenas de inferencia válidas.&lt;/p&gt;
&lt;p&gt;El análisis establece que la principal limitación no radica en las
capacidades de percepción visual sino en la insuficiencia del
razonamiento simbólico formal. Los autores concluyen que los MLLMs
actuales no constituyen demostradores automáticos efectivos para
problemas multimodales, identificando la brecha entre comprensión
multimodal y razonamiento lógico como el desafío fundamental a resolver.&lt;/p&gt;
&lt;p&gt;MATP-BENCH se posiciona como el primer banco de prueba estándar para
este dominio, proporcionando una base metodológica para la evaluación de
futuros desarrollos en demostración automática multimodal.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>CoqProver</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>MLLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</guid><pubDate>Fri, 13 Jun 2025 15:10:00 GMT</pubDate></item><item><title>El futuro del razonamiento matemático: Integrando IA y Lean</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia "&lt;a href="https://youtu.be/LylJBfvVzyw"&gt;Will computers prove theorems?&lt;/a&gt;", &lt;a href="https://profiles.imperial.ac.uk/k.buzzard"&gt;Kevin Buzzard&lt;/a&gt;
plantea que los ordenadores ya demuestran teoremas, pero la pregunta
crucial es cómo pueden transformar la investigación matemática. Aunque
reconoce la utilidad de las herramientas actuales como las redes
neuronales para identificar patrones, su aplicación permanece
limitada. Los modelos de lenguaje como ChatGPT, por su parte, pueden
ofrecer ideas valiosas, pero fracasan rotundamente en el razonamiento
lógico: tienden a "alucinar" o inventar detalles para parecer
convincentes, lo que los convierte en herramientas poco confiables para
las matemáticas rigurosas.&lt;/p&gt;
&lt;p&gt;La solución que propone Buzzard para superar estas limitaciones radica
en la sinergia entre la inteligencia artificial y los asistentes de
demostración formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Su propuesta consiste en entrenar modelos
de IA para que generen pruebas directamente en código de Lean, en lugar
de utilizar lenguaje natural. De este modo, el asistente de demostración
funciona como un verificador infalible: cualquier argumento lógicamente
incorrecto será rechazado automáticamente por el sistema. Esta
metodología obligaría a la IA a evolucionar desde la mera imitación de
patrones hacia la construcción de razonamientos lógicamente
verificables.&lt;/p&gt;
&lt;p&gt;No obstante, el principal obstáculo para materializar esta visión es la
escasez de matemáticas modernas y avanzadas formalizadas en Lean,
elementos esenciales para el entrenamiento de estos modelos. Buzzard
concluye con un llamamiento directo a la comunidad matemática: considera
que es responsabilidad de los investigadores emprender la tarea
fundamental de formalizar el conocimiento de sus respectivos campos, tal
como él mismo está haciendo con el &lt;a href="https://imperialcollegelondon.github.io/FLT/"&gt;último teorema de Fermat&lt;/a&gt;. Argumenta
que este esfuerzo resulta crucial para desarrollar las herramientas que
revolucionarán la disciplina, a pesar de que el sistema académico actual
no reconozca ni recompense adecuadamente este tipo de contribuciones.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</guid><pubDate>Wed, 11 Jun 2025 15:26:00 GMT</pubDate></item><item><title>Readings shared June 10, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 10 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lawrencecpaulson.github.io//2025/06/09/Inductive_Definitions.html"&gt;Inductive definitions&lt;/a&gt;. ~ Lawrence Paulson. #ITP #IsabelleHOL #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project: advancing collaborative mathematical research at scale&lt;/a&gt;. ~ Terence Tao et als. #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathscholar.org/2025/06/new-ai-stuns-mathematicians-with-its-problem-solving-skill/"&gt;New AI stuns mathematicians with its problem-solving skill&lt;/a&gt;. ~ David H Bailey. #AI #LLMs #Math #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07477"&gt;Premise selection for a Lean hammer&lt;/a&gt;. ~ Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck. #ITP #LeanProver #AI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04592v1"&gt;Safe: Enhancing mathematical reasoning in large language models via retrospective step-aware formal verification&lt;/a&gt;. ~ Chengwu Liu et als. #LLMs #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;. ~ Thomas Hubert. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative discovery&lt;/a&gt;. ~ Mateja Jamnik. #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04575v1"&gt;Are LLMs reliable translators of logical reasoning across lexically diversified contexts?&lt;/a&gt; ~ Qingchuan Li et als. #LLMs #Math #ATP #Prover9&lt;/li&gt;
&lt;li&gt;&lt;a href="https://coyotetracks.org/blog/dr-neckbeard-emacs/"&gt;Dr. Neckbeard, or how I learned to stop worrying and love Emacs&lt;/a&gt;. ~ Watts Martin. #Emacs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bib.us.es/sites/bib3.us.es/files/investiga52.pdf"&gt;Revistas, editoriales y congresos depredadores&lt;/a&gt;. #Investigación&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/"&gt;AlphaProof: Aprendizaje por refuerzo aplicado a la demostración matemática&lt;/a&gt;. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/"&gt;El futuro de las matemáticas: Descubrimiento colaborativo entre humanos y máquinas&lt;/a&gt;. #AIforMath #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/"&gt;El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)&lt;/a&gt;. #AIforMath #ITP #LeanProver #Math&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>AlphaProof</category><category>ATP</category><category>Emacs</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Prover9</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</guid><pubDate>Wed, 11 Jun 2025 09:06:00 GMT</pubDate></item><item><title>El futuro de las matemáticas - Descubrimiento colaborativo entre humanos y máquinas</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Ayer, en su conferencia "&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative
discovery&lt;/a&gt;", &lt;a href="https://www.cl.cam.ac.uk/~mj201/"&gt;Mateja Jamnik&lt;/a&gt; presentó una visión de la inteligencia
artificial no como una simple herramienta para resolver problemas, sino
como un socio colaborativo en el descubrimiento matemático. Su trabajo
explora cómo las máquinas pueden proponer ideas y acelerar la
investigación. A través de un estudio empírico con matemáticos, demostró
que la interacción humano-IA es compleja; una respuesta de la IA no
necesita ser perfectamente correcta para ser útil, ya que incluso ideas
parcialmente erróneas pueden inspirar nuevas vías de pensamiento,
mientras que respuestas correctas pero verbosas pueden resultar
inútiles.&lt;/p&gt;
&lt;p&gt;El núcleo técnico de su propuesta, materializado en trabajos como su
artículo "&lt;a href="https://openreview.net/pdf?id=SMa9EAovKMC"&gt;Draft, sketch, and prove: Guiding formal theorem provers with
informal proofs&lt;/a&gt;", es un ciclo auto-mejorable que integra el vasto
conocimiento matemático informal. A través de la arquitectura ‘Borrador,
Esquema y Prueba’ descrita en dicho artículo, la IA traduce pruebas
humanas a un formato formal y riguroso. Este ciclo culmina en un sistema
‘conjeturador-demostrador’ que genera progresivamente nuevas conjeturas,
las evalúa según su capacidad para ayudar a resolver problemas más
difíciles y utiliza las mejores para mejorar continuamente, acercándose
así a la resolución de teoremas que antes eran inaccesibles.&lt;/p&gt;
&lt;p&gt;El objetivo final es integrar plenamente al ser humano en este ciclo de
descubrimiento. Jamnik imagina un futuro donde los matemáticos
interactúen con este sistema para proponer y evaluar conjeturas, guiando
la dirección de la investigación. Su conclusión es que la IA no
reemplazará a los matemáticos, sino que los potenciará, creando una
sinergia entre la intuición humana y la capacidad de la máquina. &lt;strong&gt;El
futuro de las matemáticas, según su visión, es una era de descubrimiento
colaborativo entre humanos y máquinas.&lt;/strong&gt;&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</guid><pubDate>Tue, 10 Jun 2025 17:00:00 GMT</pubDate></item><item><title>AlphaProof - Aprendizaje por refuerzo aplicado a la demostración matemática</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia de ayer "&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;",
Thomas Hubert de Google DeepMind presentó &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;AlphaProof&lt;/a&gt;, un sistema de
inteligencia artificial que aplica los principios del &lt;a href="https://en.wikipedia.org/wiki/Reinforcement_learning"&gt;aprendizaje por
refuerzo&lt;/a&gt; (RL, del inglés "&lt;em&gt;Reinforcement learning&lt;/em&gt;") al dominio de las
matemáticas formales. El concepto fundamental radica en que los
asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; proporcionan el entorno perfecto
para el RL: un espacio de experimentación masiva con retroalimentación
inequívoca (una prueba matemática es correcta o incorrecta, sin
ambigüedades). Siguiendo el paradigma exitoso de sistemas como AlphaGo
Zero, AlphaProof está diseñado para generar conocimiento matemático de
forma autónoma, trascendiendo la mera imitación de demostraciones
humanas preexistentes.&lt;/p&gt;
&lt;p&gt;La arquitectura de AlphaProof se estructura en un proceso de múltiples
fases que combina diferentes técnicas de aprendizaje
automático. Inicialmente, emplea modelos de lenguaje para autoformalizar
problemas matemáticos expresados en lenguaje natural hacia el código
formal de Lean, generando así un extenso conjunto de datos de
entrenamiento. Su modelo demostrador experimenta dos etapas: primero, un
entrenamiento supervisado utilizando la biblioteca &lt;a href="https://leanprover-community.github.io/mathlib-overview.html"&gt;mathlib&lt;/a&gt;, seguido de
un refinamiento intensivo mediante RL que resuelve millones de problemas
matemáticos. Para desafíos particularmente complejos —como los de la
Olimpiada Internacional de Matemáticas (IMO)—, el sistema implementa una
estrategia de adaptación en tiempo real, generando y resolviendo
múltiples variantes de un problema para desarrollar gradualmente la
intuición necesaria.&lt;/p&gt;
&lt;p&gt;Los resultados validan el potencial transformador de AlphaProof como
herramienta matemática colaborativa. El sistema alcanzó una puntuación
equivalente a una &lt;a href="https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/"&gt;medalla de plata en la IMO&lt;/a&gt; y, durante una demostración
en vivo durante la conferencia, asistió exitosamente a un matemático a
completar los pasos de una prueba compleja relacionada con la función
zeta de Riemann. Hubert enfatiza que el objetivo trasciende las
competiciones académicas: la meta fundamental es contribuir
significativamente a la investigación matemática contemporánea,
convirtiendo AlphaProof en una útil para la comunidad matemática que
facilite el descubrimiento y verificación de nuevas verdades
matemáticas.&lt;/p&gt;</description><category>AI</category><category>AlphaProof</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>RL</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/</guid><pubDate>Tue, 10 Jun 2025 11:50:00 GMT</pubDate></item><item><title>Readings shared June 9, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 9 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://emilyriehl.github.io/files/invisible.pdf"&gt;Formalizing invisible mathematics: case studies from higher category theory&lt;/a&gt;. ~ Emily Riehl. #ITP #LeanProver #Math #CategoryTheory&lt;/li&gt;
&lt;li&gt;&lt;a href="https://provables.github.io/sequencelib/"&gt;Sequencelib: A platform for formalizing in Lean 4 sequences from "The On-Line Encyclopedia of Integer Sequences" (OEIS)&lt;/a&gt;. ~ Walter Moreira, Joe Stubbs. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.scientificamerican.com/article/inside-the-secret-meeting-where-mathematicians-struggled-to-outsmart-ai/"&gt;At secret math meeting, researchers struggle to outsmart AI&lt;/a&gt;. ~ Lyndie Chiou. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mmhaskell.com/blog/2025/6/9/spatial-reasoning-with-zigzag-patterns"&gt;Comparing code: Spatial reasoning with zigzag patterns! ~ James Bowen&lt;/a&gt;. #Haskell #FunctionalProgramming #Rust&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@kenichisasagawa/exploring-topological-spaces-with-prolog-a-practical-approach-using-mathematics-with-prolog-b5806bb8b98f"&gt;Exploring topological spaces with Prolog: A practical approach using "Mathematics with Prolog"&lt;/a&gt;. ~ Kenichi Sasagawa. #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2108.09893"&gt;Teaching and learning mathematics with Prolog&lt;/a&gt;. ~ Tom Bensky (2021). #Prolog #LogicProgramming #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/09-evaluando-la-ia-con-problemas-matematicos-ineditos-de-nivel-experto/"&gt;Evaluando la IA con problemas matemáticos inéditos de nivel experto&lt;/a&gt;. #AIforMath #AI #LLMs #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/li-12"&gt;Curso "Lógica informática (2012-13)"&lt;/a&gt;. #Lógica #ProgramaciónLógica #Prolog&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/lmf-12"&gt;Curso "Lógica matemática y fundamentos (2012-13)"&lt;/a&gt;. #Lógica #Haskell #ProgramaciónFuncional #Isabelle/HOL&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>CategoryTheory</category><category>FunctionalProgramming</category><category>Haskell</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>LogicProgramming</category><category>Math</category><category>Prolog</category><category>Rust</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/09-readings_shared_06-09-25/</guid><pubDate>Tue, 10 Jun 2025 04:00:00 GMT</pubDate></item><item><title>Readings shared June 8, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 8 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf"&gt;The illusion of thinking: Understanding the strengths and limitations of reasoning models via the lens of problem complexity&lt;/a&gt;. ~ Parshin Shojaee et als. #LLMs #Reasoning&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/07-mas-alla-de-la-ilusion-de-pensar/"&gt;Más allá de la "ilusión de pensar"&lt;/a&gt;. #LLMs #Reasoning #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/"&gt;AutoGPS: Un sistema neuro-simbólico para la geometría&lt;/a&gt;. #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/cursos/i1m-12"&gt;Curso "Informática (2012-13)"&lt;/a&gt;. #Haskell #ProgramaciónFuncional #Algorítmica #CálculoSimbólico #Maxima&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>Algorithms</category><category>CAS</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Maxima</category><category>Reasoning</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/08-readings_shared_06-08-25/</guid><pubDate>Sun, 08 Jun 2025 04:00:00 GMT</pubDate></item><item><title>AutoGPS - Un sistema neuro-simbólico para la geometría</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El artículo &lt;a href="https://arxiv.org/pdf/2505.23381"&gt;AutoGPS: Automated Geometry Problem Solving via Multimodal
Formalization and Deductive Reasoning&lt;/a&gt;
presenta &lt;a href="https://jayce-ping.github.io/AutoGPS-homepage/"&gt;AutoGPS&lt;/a&gt;, un
sistema paradigmático para la geometría. Este trabajo aborda la
dicotomía fundamental entre los modelos neuronales, que destacan en la
interpretación multimodal pero carecen de fiabilidad lógica, y los
métodos simbólicos, que garantizan el rigor pero son ineficaces para
formalizar problemas a partir de entradas complejas. AutoGPS resuelve
este dilema mediante un marco neuro-simbólico: un &lt;strong&gt;formalizador de
problemas multimodales&lt;/strong&gt; (MPF) traduce la entrada visual y textual a un
lenguaje lógico, sobre el cual opera un &lt;strong&gt;razonador simbólico
deductivo&lt;/strong&gt; (DSR) para derivar la solución.&lt;/p&gt;
&lt;p&gt;La innovación crucial reside en la interacción bidireccional entre ambos
componentes. El DSR no se limita a resolver el problema formalizado,
sino que actúa como un verificador, validando la interpretación del MPF
y pudiendo solicitarle correcciones. Este bucle de retroalimentación
garantiza la consistencia lógica de todo el proceso, fusionando la
capacidad heurística del modelo neuronal con el rigor inflexible del
razonamiento deductivo.&lt;/p&gt;
&lt;p&gt;Como resultado, AutoGPS establece un nuevo estado del arte en los
benchmarks de referencia, produciendo derivaciones que no solo son
correctas, sino también concisas y legibles para un humano. De este
modo, redefine el estándar de fiabilidad e interpretabilidad en la
resolución automática de problemas matemáticos. La &lt;a href="https://jayce-ping.github.io/AutoGPS-homepage/"&gt;página del proyecto&lt;/a&gt;
ofrece ejemplos ilustrativos de su funcionamiento.&lt;/p&gt;</description><category>AI</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/08-autogps-un_sistema_neuro-simbolico-para-geometria/</guid><pubDate>Sun, 08 Jun 2025 03:00:00 GMT</pubDate></item></channel></rss>