<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Vestigium</title><link>https://jaalonso.github.io/vestigium/</link><description>Ejercicios de programación con Haskell y Python.</description><atom:link href="https://jaalonso.github.io/vestigium/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>es</language><copyright>Contents © 2025 &lt;a href="mailto:"&gt;José A. Alonso&lt;/a&gt; 
&lt;a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;
&lt;img alt="Creative Commons License BY-NC-SA"
style="border-width:0; margin-bottom:12px;"
src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"&gt;&lt;/a&gt;</copyright><lastBuildDate>Sat, 14 Jun 2025 09:16:14 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Readings shared June 13, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 13 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2503.00959"&gt;Formalizing zeta and L-functions in Lean&lt;/a&gt;. ~ David Loeffler, Michael Stoll. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="http://adam.chlipala.net/theses/teshome.pdf"&gt;Formal verification of relational algebra transformations in Fiat2 using Coq&lt;/a&gt;. ~ Christian Teshome. #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10048"&gt;Growing a modular framework for modal systems - HOLMS: a HOL Light library&lt;/a&gt;. ~ Antonella Bilotta. #ITP #HOL&lt;sub&gt;Light&lt;/sub&gt; #Logic #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.morph.so/blog/trinity"&gt;Trinity: an autoformalization system for verified superintelligence&lt;/a&gt;. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/morph-labs/lean-abc-true-almost-always"&gt;The abc conjecture almost always — autoformalized&lt;/a&gt;. ~ Jesse Michael Han et als. #Autoformalization #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt; ~ Zhitao He et als. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural languages&lt;/a&gt;. ~ Yu Xuejun et als. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.10558"&gt;StepProof: Step-by-step verification of natural language mathematical proofs&lt;/a&gt;. ~ Xiaolin Hu, Qinghua Zhou, Bogdan Grechuk, Ivan Y. Tyukin. #LLMs #ITP #IsabelleHOL #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/"&gt;Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»&lt;/a&gt;. #AI #MLLMs #Math #ITP #IsabelleHOL #LeanProver #CoqProver #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/"&gt;Reseña de «Mathesis: Towards formal theorem proving from natural languages»&lt;/a&gt;. #AI #LLMs #Math #ITP #LeanProver #AIforMath&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>Autoformalization</category><category>CoqProver</category><category>HOL&lt;sub&gt;Light&lt;/sub&gt;</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>MLLMs</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/14-readings_shared_06-13-25/</guid><pubDate>Sat, 14 Jun 2025 09:15:00 GMT</pubDate></item><item><title>Reseña de «Mathesis: Towards formal theorem proving from natural languages»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.07047"&gt;Mathesis: Towards formal theorem proving from natural
languages&lt;/a&gt;», se aborda la limitación clave de los demostradores de
teoremas: su dependencia de enunciados ya formalizados. El trabajo se
centra en el paso crítico de la 'autoformalización' —la traducción a un
lenguaje formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;— y presenta Mathesis, un sistema integral
diseñado para automatizar todo el proceso.&lt;/p&gt;
&lt;p&gt;El sistema introduce un Mathesis-Autoformalizer entrenado mediante
aprendizaje por refuerzo para optimizar la traducción a código Lean. Su
rendimiento se evalúa con LeanScorer, y se pone a prueba en
Gaokao-Formal, un nuevo y exigente banco de pruebas. Finalmente,
Mathesis-Prover genera la demostración completa en Lean, asegurando que
la prueba final sea verificable.&lt;/p&gt;
&lt;p&gt;Los resultados demuestran que Mathesis alcanza un rendimiento de
vanguardia en varios bancos de prueba. El análisis revela una conclusión
crucial: las mejoras en la autoformalización impactan el éxito final
mucho más que las mejoras en el demostrador. Esto se explica porque si
el problema se traduce incorrectamente a código Lean, el demostrador
recibe una tarea mal planteada y no puede generar una prueba válida, sin
importar su potencia. El trabajo confirma así que una traducción inicial
de alta calidad es el factor más determinante para el éxito del proceso.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-mathesis-towards-formal-theorem-proving-from-natural-languages/</guid><pubDate>Fri, 13 Jun 2025 16:35:00 GMT</pubDate></item><item><title>Reseña de «MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?»</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En el artículo «&lt;a href="https://arxiv.org/abs/2506.06034"&gt;MATP-BENCH: Can MLLM be a good automated theorem prover for multimodal problems?&lt;/a&gt;», los autores investigan la aplicabilidad de
los modelos de lenguaje grandes multimodales (MLLMs) al problema de la
demostración automática de teoremas que involucran componentes tanto
textuales como visuales. Motivados por las limitaciones de los enfoques
puramente textuales en dominios como la geometría, donde los diagramas
constituyen información esencial, desarrollan un marco de evaluación
sistemático para esta clase de problemas.&lt;/p&gt;
&lt;p&gt;La contribución principal consiste en la construcción de &lt;a href="https://github.com/Zhitao-He/MATPBench"&gt;MATP-BENCH&lt;/a&gt;, un
conjunto de datos que contiene más de 1000 problemas matemáticos
multimodales formalizados en tres asistentes de demostración: &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean 4&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/Rocq"&gt;Coq&lt;/a&gt; e &lt;a href="https://en.wikipedia.org/wiki/Isabelle_(proof_assistant)"&gt;Isabelle/HOL&lt;/a&gt;. El corpus abarca problemas de complejidad variable,
desde el nivel de secundaria hasta competiciones matemáticas avanzadas,
proporcionando así un banco de pruebas comprehensivo para evaluar
capacidades de razonamiento multimodal.&lt;/p&gt;
&lt;p&gt;Los experimentos incluyen seis modelos representativos: tres con
capacidades especializadas de razonamiento (OpenAI-o1,
Claude-3.7-Sonnet-Thinking, Gemini-2.0-Flash-Thinking) y tres sin estas
capacidades (GPT-4.1, Qwen2.5-VL-Instruct-70B,
Llama3.2-Vision-Instruct-11B). Los resultados revelan que, si bien los
modelos demuestran competencia en la comprensión de problemas y
formalización de enunciados, exhiben deficiencias significativas en la
construcción de cadenas de inferencia válidas.&lt;/p&gt;
&lt;p&gt;El análisis establece que la principal limitación no radica en las
capacidades de percepción visual sino en la insuficiencia del
razonamiento simbólico formal. Los autores concluyen que los MLLMs
actuales no constituyen demostradores automáticos efectivos para
problemas multimodales, identificando la brecha entre comprensión
multimodal y razonamiento lógico como el desafío fundamental a resolver.&lt;/p&gt;
&lt;p&gt;MATP-BENCH se posiciona como el primer banco de prueba estándar para
este dominio, proporcionando una base metodológica para la evaluación de
futuros desarrollos en demostración automática multimodal.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>CoqProver</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>MLLMs</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-resena-de-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimodal-problems/</guid><pubDate>Fri, 13 Jun 2025 15:10:00 GMT</pubDate></item><item><title>Readings shared June 12, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 12 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/R2t9ZRWiWEk"&gt;Formalizing the divided power envelope in Lean&lt;/a&gt;. ~ María Inés de Frutos Fernández. #ITP #LeanProver #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/YtbfIjgzNDI"&gt;Lean meta-theory: The proofs behind the proofs&lt;/a&gt;. ~ Mario Carneiro. #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/litexlang/golitex"&gt;Litex: Scale formal reasoning in AI age&lt;/a&gt;. ~ Jiachen Shen. #Logic #ATP #LitexLang&lt;/li&gt;
&lt;li&gt;&lt;a href="https://neus-2025.github.io/files/papers/paper_33.pdf"&gt;Lean Copilot: Large language models as copilots for theorem proving in Lean&lt;/a&gt;. ~ Peiyang Song, Kaiyu Yang, Anima Anandkumar. #ITP #LeanProver #LLMs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3713082.3730382"&gt;Can large language models verify system software? A case study using FSCQ as a benchmark&lt;/a&gt;. ~ Jianxing Qin et als. #LLMs #ITP #CoqProver #Rocq&lt;/li&gt;
&lt;li&gt;&lt;a href="https://muratkasimov.art/Ya/Articles/Reinventing-records-and-variants"&gt;Reinventing records and variants&lt;/a&gt;. ~ Murat Kasimov. #Haskell #FunctionalProgramming&lt;/li&gt;
&lt;/ul&gt;</description><category>ATP</category><category>CoqProver</category><category>FunctionalProgramming</category><category>Haskell</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Logic</category><category>Math</category><category>Rocq</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/13-readings_shared_06-12-25/</guid><pubDate>Fri, 13 Jun 2025 08:40:00 GMT</pubDate></item><item><title>Readings shared June 11, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/12-readings_shared_06-11-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 11 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.08321"&gt;LeanTutor: A formally-verified AI tutor for mathematical proofs&lt;/a&gt;. ~ Manooshree Patel et als. #ITP #LeanProver #Math #AIforMath #Teaching&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/nielsvoss/lean-pitfalls"&gt;Common Lean pitfalls&lt;/a&gt;. ~ Niels Voss. #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/"&gt;Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library&lt;/a&gt;. ~ Brenda Potts. #ITP #LeanProver #RustLang&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.08294v1"&gt;Z3Guide: A scalable, student-centered, and extensible educational environment for logic modeling&lt;/a&gt;. ~ Ruanqianqian Huang, Ayana Monroe, Peli de Halleux, Sorin Lerner, Nikolaj Bjørner. #Logic #SMT #Z3 #Teaching&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hal.univ-lille.fr/hal-05061202v1/file/main.pdf"&gt;Martin Davis: An overview of his work in logic, computer science, and philosophy&lt;/a&gt;. ~ Liesbeth De Mol, Yuri V. Matiyasevich, Eugenio G. Omodeo, Alberto Policriti, Wilfried Sieg, Elaine J. Weyuker. #Logic #Math #CompSci&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/"&gt;El futuro del razonamiento matemático: Integrando IA y Lean&lt;/a&gt;. #IA #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/"&gt;Reseña de 'LeanTutor: A formally-verified AI tutor for mathematical proofs'&lt;/a&gt;. #ITP #LeanProver #Math #AIforMath #Teaching&lt;/li&gt;
&lt;/ul&gt;</description><category>AIforMath</category><category>CompSci</category><category>IA</category><category>ITP</category><category>LeanProver</category><category>Logic</category><category>Math</category><category>RustLang</category><category>SMT</category><category>Z3</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/12-readings_shared_06-11-25/</guid><pubDate>Thu, 12 Jun 2025 06:16:00 GMT</pubDate></item><item><title>Reseña de 'LeanTutor: A formally-verified AI tutor for mathematical proofs'</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;El artículo "&lt;a href="https://arxiv.org/abs/2506.08321"&gt;LeanTutor: A formally-verified AI tutor for mathematical
proofs&lt;/a&gt;" aborda un problema común en la educación matemática: los
estudiantes tienen dificultades para aprender demostraciones.
Actualmente existen dos tipos de herramientas, pero ninguna funciona
bien para enseñar. Los chatbots como ChatGPT son fáciles de usar pero
dan respuestas directas o incorrectas, sin ayudar realmente al
aprendizaje. Los asistentes de demostración como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt; verifican las
matemáticas perfectamente, pero son demasiado complicados para
principiantes. Se necesita una herramienta que combine lo mejor de
ambos: la facilidad del lenguaje natural y la precisión de la
verificación formal.&lt;/p&gt;
&lt;p&gt;Los autores crearon LeanTutor, un sistema que funciona como tutor
inteligente combinando lenguaje natural con verificación formal. El
sistema tiene tres partes que trabajan juntas. Primero, el
'autoformalizador' toma lo que escribe el estudiante en lenguaje normal
y lo convierte a código Lean para verificar si es correcto. Si hay un
error, el 'generador del siguiente paso' calcula cuál sería la respuesta
correcta. Finalmente, el 'generador de retroalimentación' convierte esta
información técnica en consejos útiles para el estudiante, dándole
pistas sin revelar directamente la solución.&lt;/p&gt;
&lt;p&gt;Los investigadores probaron LeanTutor usando un nuevo conjunto de datos
llamado PeanoBench y los resultados fueron positivos. El sistema logró
convertir correctamente la mayoría de los pasos que escribían los
estudiantes y detectó muchos errores. Cuando compararon la
retroalimentación de LeanTutor con otros sistemas, encontraron que era
más precisa y útil para los estudiantes. Los autores concluyen que este
enfoque de combinar IA conversacional con verificación formal es una
buena dirección para crear mejores herramientas educativas.&lt;/p&gt;
&lt;p&gt;Este trabajo presenta una idea muy buena para mejorar la educación
matemática. La principal fortaleza es que logra combinar de manera
inteligente la facilidad de uso del lenguaje natural con la precisión
matemática de Lean. Sin embargo, también tiene algunas limitaciones
importantes. El sistema necesita tener de antemano la solución correcta
del problema, y asume que los pasos del estudiante se pueden traducir
directamente a código Lean, lo que podría no funcionar en situaciones
más complejas. A pesar de estas limitaciones, LeanTutor es un buen
primer paso que muestra cómo la IA puede ayudar a enseñar matemáticas de
forma más efectiva y segura.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><category>Teaching</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-resena-de-leantutor-a-formally-verified-ai-tutor-for-mathematical-proofs/</guid><pubDate>Wed, 11 Jun 2025 17:26:00 GMT</pubDate></item><item><title>El futuro del razonamiento matemático: Integrando IA y Lean</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;En su conferencia "&lt;a href="https://youtu.be/LylJBfvVzyw"&gt;Will computers prove theorems?&lt;/a&gt;", &lt;a href="https://profiles.imperial.ac.uk/k.buzzard"&gt;Kevin Buzzard&lt;/a&gt;
plantea que los ordenadores ya demuestran teoremas, pero la pregunta
crucial es cómo pueden transformar la investigación matemática. Aunque
reconoce la utilidad de las herramientas actuales como las redes
neuronales para identificar patrones, su aplicación permanece
limitada. Los modelos de lenguaje como ChatGPT, por su parte, pueden
ofrecer ideas valiosas, pero fracasan rotundamente en el razonamiento
lógico: tienden a "alucinar" o inventar detalles para parecer
convincentes, lo que los convierte en herramientas poco confiables para
las matemáticas rigurosas.&lt;/p&gt;
&lt;p&gt;La solución que propone Buzzard para superar estas limitaciones radica
en la sinergia entre la inteligencia artificial y los asistentes de
demostración formal como &lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;. Su propuesta consiste en entrenar modelos
de IA para que generen pruebas directamente en código de Lean, en lugar
de utilizar lenguaje natural. De este modo, el asistente de demostración
funciona como un verificador infalible: cualquier argumento lógicamente
incorrecto será rechazado automáticamente por el sistema. Esta
metodología obligaría a la IA a evolucionar desde la mera imitación de
patrones hacia la construcción de razonamientos lógicamente
verificables.&lt;/p&gt;
&lt;p&gt;No obstante, el principal obstáculo para materializar esta visión es la
escasez de matemáticas modernas y avanzadas formalizadas en Lean,
elementos esenciales para el entrenamiento de estos modelos. Buzzard
concluye con un llamamiento directo a la comunidad matemática: considera
que es responsabilidad de los investigadores emprender la tarea
fundamental de formalizar el conocimiento de sus respectivos campos, tal
como él mismo está haciendo con el &lt;a href="https://imperialcollegelondon.github.io/FLT/"&gt;último teorema de Fermat&lt;/a&gt;. Argumenta
que este esfuerzo resulta crucial para desarrollar las herramientas que
revolucionarán la disciplina, a pesar de que el sistema académico actual
no reconozca ni recompense adecuadamente este tipo de contribuciones.&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>ITP</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-el-futuro-del-razonamiento-matematico-integrando-ia-y-lean/</guid><pubDate>Wed, 11 Jun 2025 15:26:00 GMT</pubDate></item><item><title>Readings shared June 10, 2025</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;The readings shared in &lt;a href="https://bsky.app/profile/jalonso.bsky.social"&gt;Bluesky&lt;/a&gt; on 10 June 2025 are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://lawrencecpaulson.github.io//2025/06/09/Inductive_Definitions.html"&gt;Inductive definitions&lt;/a&gt;. ~ Lawrence Paulson. #ITP #IsabelleHOL #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project: advancing collaborative mathematical research at scale&lt;/a&gt;. ~ Terence Tao et als. #ITP #LeanProver #Math #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mathscholar.org/2025/06/new-ai-stuns-mathematicians-with-its-problem-solving-skill/"&gt;New AI stuns mathematicians with its problem-solving skill&lt;/a&gt;. ~ David H Bailey. #AI #LLMs #Math #AIforMath #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.07477"&gt;Premise selection for a Lean hammer&lt;/a&gt;. ~ Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck. #ITP #LeanProver #AI&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04592v1"&gt;Safe: Enhancing mathematical reasoning in large language models via retrospective step-aware formal verification&lt;/a&gt;. ~ Chengwu Liu et als. #LLMs #Math #ITP #LeanProver&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/xZIqn4V6O0A"&gt;AlphaProof: When RL meets formal maths&lt;/a&gt;. ~ Thomas Hubert. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative discovery&lt;/a&gt;. ~ Mateja Jamnik. #AIforMath&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/2506.04575v1"&gt;Are LLMs reliable translators of logical reasoning across lexically diversified contexts?&lt;/a&gt; ~ Qingchuan Li et als. #LLMs #Math #ATP #Prover9&lt;/li&gt;
&lt;li&gt;&lt;a href="https://coyotetracks.org/blog/dr-neckbeard-emacs/"&gt;Dr. Neckbeard, or how I learned to stop worrying and love Emacs&lt;/a&gt;. ~ Watts Martin. #Emacs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://bib.us.es/sites/bib3.us.es/files/investiga52.pdf"&gt;Revistas, editoriales y congresos depredadores&lt;/a&gt;. #Investigación&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-alphaproof-aprendizaje-por-refuerzo-aplicado-a-la-demostracion-matematica/"&gt;AlphaProof: Aprendizaje por refuerzo aplicado a la demostración matemática&lt;/a&gt;. #AI #Math #AIforMath #ITP #LeanProver #AlphaProof&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/"&gt;El futuro de las matemáticas: Descubrimiento colaborativo entre humanos y máquinas&lt;/a&gt;. #AIforMath #AI #Math&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/"&gt;El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)&lt;/a&gt;. #AIforMath #ITP #LeanProver #Math&lt;/li&gt;
&lt;/ul&gt;</description><category>AI</category><category>AIforMath</category><category>AlphaProof</category><category>ATP</category><category>Emacs</category><category>IsabelleHOL</category><category>ITP</category><category>LeanProver</category><category>LLMs</category><category>Math</category><category>Prover9</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/11-readings_shared_06-10-25/</guid><pubDate>Wed, 11 Jun 2025 09:06:00 GMT</pubDate></item><item><title>El proyecto ETP (Un caso de estudio en investigación matemática colaborativa y formalizada)</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Hoy, en su conferencia "&lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2025/06/math-experiments.pdf"&gt;The equational theories project&lt;/a&gt;", &lt;a href="https://en.wikipedia.org/wiki/Terence_Tao"&gt;Terence Tao&lt;/a&gt;
defendió que la investigación matemática debe evolucionar hacia un
modelo colaborativo a gran escala, semejante al empleado en otras
disciplinas científicas. Esta transformación requiere el uso de
herramientas modernas como plataformas colaborativas (&lt;a href="https://github.com/teorth/equational_theories"&gt;GitHub&lt;/a&gt;),
asistentes de prueba formales (&lt;a href="https://en.wikipedia.org/wiki/Lean_(proof_assistant)"&gt;Lean&lt;/a&gt;) y automatización mediante
inteligencia artificial. El proyecto &lt;a href="https://teorth.github.io/equational_theories/"&gt;ETP (Equational Theories Project)&lt;/a&gt;
constituye un ejemplo paradigmático de esta nueva aproximación a la
investigación matemática.&lt;/p&gt;
&lt;p&gt;El proyecto nació de una pregunta aparentemente simple planteada en el
foro MathOverflow, pero pronto adquirió una dimensión extraordinaria:
mapear completamente el "gráfico de implicaciones" entre 4,692 leyes
algebraicas únicas dentro de estructuras elementales denominadas
magmas. Esta ambiciosa meta implicaba resolver más de 22 millones de
problemas individuales, donde cada par de leyes requería encontrar una
prueba de implicación o desarrollar un contraejemplo que la refutara. La
magnitud descomunal de este desafío lo convertía en una tarea imposible
de abordar mediante los métodos tradicionales de investigación
individual o de pequeños equipos.&lt;/p&gt;
&lt;p&gt;La estrategia implementada por el ETP consistió en un flujo de trabajo
híbrido y descentralizado de notable innovación. La componente humana
aprovechó la creatividad de una extensa comunidad de colaboradores para
desarrollar pruebas y contraejemplos ingeniosos, mientras que la
componente computacional empleó masivamente probadores automáticos de
teoremas (ATPs) y otras herramientas para resolver millones de casos más
directos. El elemento fundamental que garantizó la integridad del
proyecto fue la formalización exhaustiva de cada resultado en el
asistente de pruebas Lean, asegurando una corrección absoluta y creando
una base de conocimiento completamente verificada y confiable.&lt;/p&gt;
&lt;p&gt;En el plazo extraordinariamente breve de tres meses, el proyecto logró
resolver prácticamente la totalidad de los 22 millones de problemas
planteados. Además, el proceso de abordar los casos más complejos
estimuló el desarrollo de técnicas matemáticas innovadoras, culminando
con la formulación de un nuevo y fascinante problema abierto. El ETP
demostró que este modelo colaborativo trasciende la mera verificación de
conocimiento existente para convertirse en un motor poderoso de
descubrimiento matemático, estableciendo así un precedente exitoso para
una investigación matemática más abierta, transparente y asistida
computacionalmente.&lt;/p&gt;</description><category>AIforMath</category><category>ITP</category><category>LeanProver</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-proyecto-etp-un-caso-de-estudio-en-investigacion-matematica-colaborativa-y-formalizada/</guid><pubDate>Tue, 10 Jun 2025 18:00:00 GMT</pubDate></item><item><title>El futuro de las matemáticas - Descubrimiento colaborativo entre humanos y máquinas</title><link>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</link><dc:creator>José A. Alonso</dc:creator><description>&lt;p&gt;Ayer, en su conferencia "&lt;a href="https://www.youtube.com/live/WdXnMrT1X_k"&gt;AI for Math: The future of collaborative
discovery&lt;/a&gt;", &lt;a href="https://www.cl.cam.ac.uk/~mj201/"&gt;Mateja Jamnik&lt;/a&gt; presentó una visión de la inteligencia
artificial no como una simple herramienta para resolver problemas, sino
como un socio colaborativo en el descubrimiento matemático. Su trabajo
explora cómo las máquinas pueden proponer ideas y acelerar la
investigación. A través de un estudio empírico con matemáticos, demostró
que la interacción humano-IA es compleja; una respuesta de la IA no
necesita ser perfectamente correcta para ser útil, ya que incluso ideas
parcialmente erróneas pueden inspirar nuevas vías de pensamiento,
mientras que respuestas correctas pero verbosas pueden resultar
inútiles.&lt;/p&gt;
&lt;p&gt;El núcleo técnico de su propuesta, materializado en trabajos como su
artículo "&lt;a href="https://openreview.net/pdf?id=SMa9EAovKMC"&gt;Draft, sketch, and prove: Guiding formal theorem provers with
informal proofs&lt;/a&gt;", es un ciclo auto-mejorable que integra el vasto
conocimiento matemático informal. A través de la arquitectura ‘Borrador,
Esquema y Prueba’ descrita en dicho artículo, la IA traduce pruebas
humanas a un formato formal y riguroso. Este ciclo culmina en un sistema
‘conjeturador-demostrador’ que genera progresivamente nuevas conjeturas,
las evalúa según su capacidad para ayudar a resolver problemas más
difíciles y utiliza las mejores para mejorar continuamente, acercándose
así a la resolución de teoremas que antes eran inaccesibles.&lt;/p&gt;
&lt;p&gt;El objetivo final es integrar plenamente al ser humano en este ciclo de
descubrimiento. Jamnik imagina un futuro donde los matemáticos
interactúen con este sistema para proponer y evaluar conjeturas, guiando
la dirección de la investigación. Su conclusión es que la IA no
reemplazará a los matemáticos, sino que los potenciará, creando una
sinergia entre la intuición humana y la capacidad de la máquina. &lt;strong&gt;El
futuro de las matemáticas, según su visión, es una era de descubrimiento
colaborativo entre humanos y máquinas.&lt;/strong&gt;&lt;/p&gt;</description><category>AI</category><category>AIforMath</category><category>Math</category><guid>https://jaalonso.github.io/vestigium/posts/2025/06/10-el-futuro-de-las-matematicas-descubrimiento-colaborativo-entre-humanos-y-maquinas/</guid><pubDate>Tue, 10 Jun 2025 17:00:00 GMT</pubDate></item></channel></rss>